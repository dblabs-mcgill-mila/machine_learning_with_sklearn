{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Disclaimers \n",
    "This material is derived from **[scikit-learn-mooc](https://github.com/INRIA/scikit-learn-mooc)** under the fair-usage clause of `Creative Commons`.\n",
    "\n",
    "*References to all the sources apart from the scikit-learn-mooc are linked*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECOND SESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Underfitting and Overfitting \n",
    "\n",
    "We will try to understand when and why a model does or does not generalize well on unseen data through the vital lens of Overfitting and Underfitting.\n",
    "\n",
    "Let us try to understand the core issue with the help of some visual examples.\n",
    "\n",
    "***\n",
    "\n",
    "We are given two prediction models, where one black point maps an input X to a target y, and we want to predict the value y from X.\n",
    "\n",
    "And of course, we have access to only these black points as the training set.\n",
    "\n",
    "On the left, we fit a simple linear model and get a line with a negative slope that detects the general trend of this cloud of data points. \n",
    "\n",
    "On the right-hand side, we fit a polynomial with a large number of degrees. This polynomial can go through all the individual black, and thus we get no prediction error.\n",
    "\n",
    "<br>\n",
    "\n",
    "Which is a better model?\n",
    "\n",
    "![right is good fit?](../figures/fit_1.png)\n",
    "\n",
    "One might intuitively pick the **right as a better fit** \n",
    "\n",
    "But as we learned in the last session, we try to find the model's generalization performance using unseen data.\n",
    "\n",
    "So when we use new data points displayed as orange data points, we see that the simple model is making the same kind of error on both the test and train data,\n",
    "but the polynomial fit, though it performs excellently on train data, makes errors outside the possible values of orange points.\n",
    "\n",
    "\n",
    "![not so right fit?](../figures/fit_2.png)\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "Let us look at another example. \n",
    "\n",
    "We are given the observation for training and say we also know the underlying model used to generate the data, which will not be possible in the real world, though.\n",
    "\n",
    "![observation and underlyting model](../figures/obervation_known_model.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "*Now, we will try to fit the polynomials of various degrees for a given set of observations*\n",
    "\n",
    "\n",
    "![polynomial models](../figures/poly_fit.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "The first one is the linear model, i.e., degree one polynomial. A degree two polynomial is a quadratic function. This one has more flexibility and can capture some of the global structure of the training set. With degree one, we have a slope as a degree of freedom. \n",
    "When we increase the degree of freedom further, we see that we manage to follow the changes in the slope of the actual generative function.\n",
    "\n",
    "And suppose we increase further to degree 9 polynomial. In that case, we see that we have this kind of wide variation of the prediction that does not reflect the original structure of the data generative process. \n",
    "\n",
    "<br>\n",
    "\n",
    "Ideally, we would like to find a model that would match approximately that dashed line, i.e., our generative function. \n",
    "\n",
    "And you see that degree two or degree five polynomials closely match the dashed line. In contrast, the degree nine polynomial is very far away, and the degree one polynomial does not find a structure. It's too constrained.\n",
    "\n",
    "![overfitting vs underfitting](../figures/over_under.png)\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**Overfitting**\n",
    "The problem with the degree nine polynomial is that this model is too complex for the limited training data provided and overfitted for this specific training set. It cannot recover the ground truth because the flexibility in the model captures the noise of the data. The limited amount of data points that we have does not make it possible to tell whether some variations are noise or an interesting structure.\n",
    "\n",
    "*To summarize, Overfitting happens when we do not have enough data points and we have too much noise in the relationship between Y and X.*\n",
    "\n",
    "<br>\n",
    "\n",
    "**Underfitting**\n",
    "In the case of degree one polynomial, i.e., the linear line, we cannot capture the non-linear structure of the dataset, i.e., the global structure of the variation of Y given X as the model is too simple, which is the underfitting problem. \n",
    "\n",
    "But the underfitting models do not suffer from the noise because they are too constrained to be able to memorize the noise. \n",
    "\n",
    "*Typically, Underfitting happens when you have plenty of data and a low noise level. You choose a model that is too constrained for this complex dataset.*\n",
    "\n",
    "<br>\n",
    "\n",
    "**So *Underfitting* and *Overfitting* describe two opposing extremes that result in poor performance, and the sweet spot of generalization performance is in between these two extremes.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression and Cross-Validation statergies\n",
    "\n",
    "Cross-validation is a critical aspect of evaluating predictive models, and thus we will keep on revisiting it.\n",
    "\n",
    "We focused on the classification problem in the last notebook and used a `K-fold` strategy.\n",
    "\n",
    "Here we will look at a **regression problem** and use the `ShuffleSplit`.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will use the california_housing dataset with the aim is to predicting the median value of houses in an area in California. \n",
    "\n",
    "The features collected are based on general real-estate and geographical information.\n",
    "\n",
    "The target to be predicted is a continuous variable and not discrete anymore. \n",
    "\n",
    "*This task is called regression.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn itself comes with some datasets which can come \n",
    "# handly to play around with sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# as frame true returns a dataframe \n",
    "housing = fetch_california_housing(\n",
    "    as_frame=True\n",
    ")\n",
    "\n",
    "data, target = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.526\n",
       "1    3.585\n",
       "2    3.521\n",
       "3    3.413\n",
       "4    3.422\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this price is in 100 thousands range ( 100 k$ )\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452.6\n",
       "1    358.5\n",
       "2    352.1\n",
       "3    341.3\n",
       "4    342.2\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert it to thousands range ( k$ )\n",
    "target *= 100\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display nice model diagram use display as diagram\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision tree learning \n",
    "\n",
    "Decision tree learning or induction of decision trees is one of the predictive modeling approaches used in statistics, data mining, and machine learning. \n",
    "\n",
    "It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). \n",
    "\n",
    "Tree models in which the target variable can take a discrete set of values are called classification trees. In these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels.\n",
    "\n",
    "Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Decision trees are among the most popular machine learning algorithms, given their intelligibility and simplicity.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "![decison tree via image](../figures/cart_tree_kyphosis.png)\n",
    "\n",
    "Above is an example tree estimating the probability of kyphosis after spinal surgery. We were given the age of the patient and the vertebra at the time of surgery. The same tree is shown in three different ways. \n",
    "\n",
    "The left one shows the colored leaves to show the probability of kyphosis after spinal surgery and the percentage of patients in the leaf.\n",
    "\n",
    "The middle one is the tree as a perspective plot. \n",
    "\n",
    "The right one is the aerial view of the middle plot. The probability of kyphosis after surgery is higher in the darker areas.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "Note from Prof. Bzdok :\n",
    "\n",
    "*\"For many problems encountered in practice, low-order interaction effects dominate. When this is the case, models that produce strong higher-order interaction effects, such as large decision trees, suffer in the accuracy.\"*\n",
    "\n",
    "[source](https://commons.wikimedia.org/wiki/File:Cart_tree_kyphosis.png)\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use a decision tree to solve this regression problem   \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6050109760817847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we start with the most basic evaluation statergy\n",
    "'''\n",
    "splitting our dataset into two subsets: a training set and a testing set;\n",
    "\n",
    "fitting the model on the training set;\n",
    "\n",
    "estimating the training error on the training set;\n",
    "\n",
    "estimating the testing error on the testing set.\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "regressor.fit(data_train, target_train)\n",
    "\n",
    "regressor.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on Score result from regression model \n",
    "\n",
    "In case of regression the `score` function returns the `coefficient of determination` of the prediction.\n",
    "\n",
    "The coefficient of determination $R^2$ is defined as $(1 - \\frac{u}{v})$, where $u$ is the residual sum of squares $(\\char` (y\\char`_true - y\\char`_pred)^{2}\\char` ).sum()$ \n",
    "\n",
    "and $v$ is the total sum of squares $(\\char` (\\char` y\\char`_true - y\\char`_true.mean()\\char` )^{2}\\char` ).sum() $. \n",
    "\n",
    "The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "A constant model that always predicts the expected value of $y$, disregarding the input features, would get a $R^2$ score of 0.0.\n",
    "\n",
    "[source](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, our regressor makes training error of 0.00 k$\n",
      "On average, our regressor makes testing error of  46.56 k$\n"
     ]
    }
   ],
   "source": [
    "# we will use the mean_absolute_error to extract the \n",
    "# error in the prediction \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "target_predicted = regressor.predict(data_test)\n",
    "\n",
    "score_test = mean_absolute_error(target_test, target_predicted)\n",
    "\n",
    "target_predicted = regressor.predict(data_train)\n",
    "\n",
    "score_train = mean_absolute_error(target_train, target_predicted)\n",
    "\n",
    "print(\n",
    "    f\"On average, our regressor makes training error of {score_train:.2f} k$\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"On average, our regressor makes testing error of  {score_test:.2f} k$\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on training and testing error \n",
    "\n",
    "We get perfect prediction with training data, i.e., with no error. \n",
    "\n",
    "It is too optimistic and almost always reveals a methodological problem of the machine learning approach.\n",
    "\n",
    "Indeed, we trained and predicted on the same dataset. \n",
    "\n",
    "Since our decision tree was fully grown i.e., we didn't modify the default parameter of the DecisionTreeRegressor. By default, it did not restrict the `max_leaf_nodes` parameter and thus stored every sample in the dataset in a leaf node. \n",
    "\n",
    "Therefore, our decision tree memorized the dataset given during fit and made no error when predicting.\n",
    "\n",
    "`This error computed is called the empirical error or training error.`\n",
    "\n",
    "The goal is always, at least for a predictive model, to train to minimize the error on data did not use during training.\n",
    "\n",
    "The testing error reported is actually about what we would expect from our model if used in a production environment.\n",
    "\n",
    "`This error is also called the generalization error or the \"true\" testing error.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stability of the cross-validation estimates\n",
    "\n",
    "By doing a single train-test split, we don't have an accurate indication regarding the robustness of the evaluation of our predictive model. In particular, if the test set is small, this estimate of the testing error will be unstable and wouldn't reflect the \"true error rate\" we would have observed with the same model on an unlimited amount of test data.\n",
    "\n",
    "For example, we could have been lucky when we did the random split of our limited dataset and isolated some of the most uncomplicated cases to predict in the testing set just by chance. In such a case, the estimation of the testing error would be overly optimistic.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Cross-validation** allows estimating the robustness of a predictive model by repeating the splitting procedure. It will give numerous training and testing errors and thus some **estimate of the variability of the model's generalization performance**.\n",
    "\n",
    "There are [different cross-validation strategies](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators), for now, we are going to focus on one called \"shuffle-split\" explosed via `ShuffleSPlit` function.\n",
    "\n",
    "At each iteration of this strategy we:\n",
    "\n",
    "- randomly shuffle the order of the samples of a copy of the entire dataset;\n",
    "- split the shuffled dataset into a train and a test set;\n",
    "- train a new model on the train set;\n",
    "- evaluate the testing error on the test set.\n",
    "\n",
    "We repeat this procedure `n_splits` times. Keep in mind that the computational cost increases with `n_splits`.\n",
    "\n",
    "***\n",
    "\n",
    "![Cross-validation diagram](../figures/shufflesplit_diagram.png)\n",
    "\n",
    "This figure shows the particular case of the shuffle-split cross-validation strategy using n_splits=5. \n",
    "\n",
    "For each cross-validation split, the procedure trains a model on all the red samples and evaluates the model's score on the blue samples. How many samples will be used for the test and train is dictated by the `train_size` and `test_size` parameter.\n",
    "\n",
    "**The critical thing to notice is that in `ShuffleSpit` one can have overlapping samples in the test set among the different splits.**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099519</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-46.882714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099165</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>-46.042903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099860</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>-47.003963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>-46.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>-47.129434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.099519    0.002369  -46.882714\n",
       "1  0.099165    0.002106  -46.042903\n",
       "2  0.099860    0.002147  -47.003963\n",
       "3  0.099813    0.002351  -46.716418\n",
       "4  0.097270    0.002168  -47.129434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "# we will do 40 splits of the data \n",
    "# test size is 30%, train size will be 70% automatically \n",
    "# once can specify both test and train size \n",
    "cv = ShuffleSplit(\n",
    "    n_splits=40,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "# now this neg_mean_absolute_error is very interesting part and we will discuss it more\n",
    "cv_results = cross_validate(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "# we save the results in dataframe for ease of visualization and manipulation.\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results in cv_results are 40\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of results in cv_results are {len(cv_results.index)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The story of neg_mean_absolute_error\n",
    "\n",
    "A score is a metric for which higher values mean better results. \n",
    "\n",
    "That's how scikit-learn looks at things, or rather the semantics of scikit-learn.\n",
    "\n",
    "On the contrary, an error is a metric for which lower values mean better results. \n",
    "\n",
    "The parameter scoring in cross_validate always expects a function that is a score.\n",
    "\n",
    "To make it easy, all error metrics in scikit-learn, like mean_absolute_error, can be transformed into a score used in cross_validate. \n",
    "\n",
    "You need to pass a string of the error metric with an additional neg_ string at the front to the parameter scoring; for instance `scoring=\"neg_mean_absolute_error\"`. \n",
    "\n",
    "In this case, the negative of the mean absolute error will be computed, equivalent to a score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099519</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-46.882714</td>\n",
       "      <td>46.882714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099165</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>-46.042903</td>\n",
       "      <td>46.042903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099860</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>-47.003963</td>\n",
       "      <td>47.003963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>-46.716418</td>\n",
       "      <td>46.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>-47.129434</td>\n",
       "      <td>47.129434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.104749</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>-44.851156</td>\n",
       "      <td>44.851156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.098930</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>-46.743777</td>\n",
       "      <td>46.743777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.098832</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>-45.926447</td>\n",
       "      <td>45.926447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.099723</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>-45.676299</td>\n",
       "      <td>45.676299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.099551</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>-45.840368</td>\n",
       "      <td>45.840368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  test_error\n",
       "0  0.099519    0.002369  -46.882714   46.882714\n",
       "1  0.099165    0.002106  -46.042903   46.042903\n",
       "2  0.099860    0.002147  -47.003963   47.003963\n",
       "3  0.099813    0.002351  -46.716418   46.716418\n",
       "4  0.097270    0.002168  -47.129434   47.129434\n",
       "5  0.104749    0.001929  -44.851156   44.851156\n",
       "6  0.098930    0.001980  -46.743777   46.743777\n",
       "7  0.098832    0.001940  -45.926447   45.926447\n",
       "8  0.099723    0.001859  -45.676299   45.676299\n",
       "9  0.099551    0.002443  -45.840368   45.840368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_error\"] = -cv_results[\"test_score\"]\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv_results[\"test_error\"].plot.hist(\n",
    "    bins=10,\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\n",
    "    \"Mean absolute error (k$)\"\n",
    ")\n",
    "\n",
    "_ = plt.title(\"Test error distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validated testing error is: 46.47 k$\n",
      "\n",
      "The standard deviation of the testing error is: 0.86 k$\n",
      "\n",
      "If we were to train a single model on the full dataset (without cross-validation)\n",
      "and then later had access to an unlimited amount of test data,\n",
      "we would expect model's true testing error to fall close in range 46.47 +/- 0.86 k$.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The mean cross-validated testing error is: \"\n",
    "    f\"{cv_results['test_error'].mean():.2f} k$\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"The standard deviation of the testing error is: \"\n",
    "    f\"{cv_results['test_error'].std():.2f} k$\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"If we were to train a single model on the full dataset (without cross-validation)\\n\"\n",
    "    f\"and then later had access to an unlimited amount of test data,\\n\"\n",
    "    f\"we would expect model's true testing error to fall close in range {cv_results['test_error'].mean():.2f} +/- {cv_results['test_error'].std():.2f} k$.\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us check the scale of the natural variability of the vector target in our dataset.\n",
    "\n",
    "target.plot.hist(bins=20, edgecolor=\"black\")\n",
    "plt.xlabel(\"Median House Value (k$)\")\n",
    "_ = plt.title(\"Target distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of the target is: 115.40 k$\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The standard deviation of the target is: {target.std():.2f} k$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on our cross-validated prediction model\n",
    "\n",
    "We notice that the mean estimate of the testing error obtained by cross-validation is slightly smaller than the natural scale of variation of the target variable. \n",
    "\n",
    "Furthermore, the standard deviation of the cross-validation estimate of the testing error is even smaller. This is a good start but not necessarily enough to decide whether the generalization performance is good enough to make our valuable prediction in practice.\n",
    "\n",
    "We recall that our model makes, on average, an error of around 47 k$. With this information and the target distribution, such an error might be acceptable when predicting houses with a 500 k$. However, it would be an issue with a house with a value of 50 k$. Thus, our metric (Mean Absolute Error) is not ideal.\n",
    "\n",
    "*Instead, we might choose a metric relative to the target value to predict: the mean absolute percentage error would have been a much better choice.*\n",
    "\n",
    "But in all cases, an error of 47 k$ might be too large to automatically use our model to tag house values without expert supervision.\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More detail regarding `cross_validate`\n",
    "\n",
    "During cross-validation, many models are trained and evaluated. Indeed, the number of elements in each array of the output of `cross_validate` results from one of these `fit`/`score` procedures. \n",
    "\n",
    "It is possible to retrieve these fitted models for each of the splits/folds by using `return_estimator=True` in `cross_validate`.\n",
    "\n",
    "We will get 40 decision tree regressors corresponding to the 40 fitted decision trees on the different folds if we enable this option. Having access to these regressors can come in handy because it allows inspecting the internal fitted parameters of these regressors.\n",
    "\n",
    "If you are only interested in the test score, scikit-learn provides a `cross_val_score` function identical to calling the `cross_validate` function and selecting the `test_score` function only.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ 1\n",
    "\n",
    "**1. A model that is underfitting:**\n",
    "\n",
    "a) is too complex and thus highly flexible\n",
    "\n",
    "b) is too constrained and thus limited by its expressivity\n",
    "\n",
    "c) often makes prediction errors, even on training samples\n",
    "\n",
    "d) focuses too much on noisy details of the training set\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. A model that is overfitting:**\n",
    "\n",
    "a) is too complex and thus highly flexible\n",
    "\n",
    "b) is too constrained and thus limited by its expressivity\n",
    "\n",
    "c) often makes prediction errors, even on training samples\n",
    "\n",
    "d) focuses too much on noisy details of the training set\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation and Learning curves \n",
    "\n",
    "We will now learn how to quantify the trade-off between overfitting and underfitting by measuring and comparing our model's train and test errors on a specific machine learning prediction problem. We will learn how train and test errors vary when we change the model's complexity, the model's parameters, and when we change the size of the training set.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Validation curves help us see the change in the complexity of a model, while the learning curve helps us see the change in the sample size.**\n",
    "\n",
    "<br>\n",
    "\n",
    "Again, we will use the example where we have our black training data points. And we have the orange data points that have not been seen during the training procedure and are just there to evaluate the test error. The goal here again is to predict Y given X. \n",
    "\n",
    "We want to quantify the quality of the model by measuring the errors in the test data, which is the fundamental objective of machine learning; to make good predictions that generalize the unseen data. \n",
    "\n",
    "But we can also quantify the error on the train data. And by contrasting the two, we will get a better picture of what happens to our model. \n",
    "\n",
    "***\n",
    "\n",
    "We again fit polynomial functions with different levels of degree. We measure the training and test errors, the average distance between the prediction curve, and the observed points, both in the training and test sets.\n",
    "\n",
    "\n",
    "We start with the linear model, i.e., degree 1 polynomial. We fit a degree 2 polynomial. We keep on moving and going up in complexity; by fitting a degree nine polynomial, we will see that the training error still decreases. Higher the degree of polynomial, or freedom, the model can go through the black data points or go close to them. But then it starts also to memorize noise elements from those black data points that are not generalized to the orange data points. And therefore, you see that the test error starts to go up.\n",
    "\n",
    "![test-train error for model with different degrees](../figures/validation_test_train_curve.png)\n",
    "\n",
    "\n",
    "When the model is too simple or too constrained, not flexible enough, both the training and test errors are up because the trainer is pushing the test error up. So here, in this case, the model is under-fitting. Then, if we increase the complexity to two, three, or five degrees, we see some nice sweet spot where the test error is minimum. But at the same time, the training error continues to go down. And if we go further, we see that we have a large gap.\n",
    "\n",
    "![sweet spot is in middle](../figures/validation_fits.png)\n",
    "\n",
    "***\n",
    "\n",
    "We can also vary the number of samples in the training set and repeat the experiment. The training and testing scores can be plotted similarly to the validation curve but we vary the number of training samples instead of varying a hyperparameter. \n",
    "\n",
    "**This curve is called the learning curve.**\n",
    "\n",
    "So if we do that for a degree nine polynomial, the one that would overfit previously, we fit it on the black data point again. And here again, you see a big gap between train and test error for a small data set. It's the case where we have overfitting because we have the gap between train and test. \n",
    "\n",
    "If we increase the number of data points, the function gets smoother, with less extreme variations. And the test error decreases sharply and goes closer to the training error. At the same time, the training error goes up a bit. So we see that maybe the model starts to underfit, maybe not. It could be something else. But more importantly, the test error is decreasing a lot and getting closer. \n",
    "\n",
    "![learning curve as data points increase](../figures/learning_curve.png)\n",
    "\n",
    "We will see that the two lines have joined with even more data points. So probably it's the case that we have enough samples, and we will recover something very close to the optimum model. And if we go beyond, you see that we make no further improvement or minimal improvement in the test error. \n",
    "\n",
    "***\n",
    "\n",
    "As we saw above, it is possible to get a degree 9 polynomial to not overfit anymore by increasing the size of the data points. And at some point, you reach diminishing returns because you still get some non-zero test error. After all, there is some noise in the generative process that you will never be able to explain just using the X variable.\n",
    "\n",
    "So this is a fundamental level of error, called the \"Bayes error rate,\" or the \"irreducible noise,\" also represented by $\\varepsilon$ that you cannot go beyond. \n",
    "\n",
    "**Bayes error rate is the error of the best model trained on an unlimited amount of data.**\n",
    "\n",
    "So we can summarize the overfit and underfit problem from two perspectives. \n",
    "\n",
    "![summary of over vs under fit](../figures/over_vs_under.png)\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***Please remember that a model is complex or not does not just depend on one specific hyperparameter, such as the degree of a polynomial, but can also depend on the class of model that we use.***\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Curve \n",
    "Model's hyperparameters are usually the key to going from an underfitting model to a model that overfits, hopefully going through a region where we can get a good balance between the two. \n",
    "\n",
    "We can acquire knowledge by plotting a curve called the validation curve. This curve can also be applied to the above experiment and varies the value of a hyperparameter. \n",
    "scikit-learn has a `validation_curve` function to vary the hyperparameters.\n",
    "\n",
    "Below we use the same function on California housing data by varying the `max_depth` parameter of `DecisionTreeRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# again reloading data and rewriting code to keep things in one view\n",
    "# this was already done earlier in this notebook\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "housing = fetch_california_housing(\n",
    "    as_frame=True\n",
    ")\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100\n",
    "\n",
    "\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "cv = ShuffleSplit(\n",
    "    n_splits=30,\n",
    "    test_size=0.2\n",
    ")\n",
    "cv_results = cross_validate(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=2\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "scores[\n",
    "    [\"train error\", \"test error\"]\n",
    "] = -cv_results[\n",
    "    [\"train_score\", \"test_score\"]\n",
    "]\n",
    "\n",
    "scores.plot.hist(\n",
    "    bins=50,\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Train and test errors distribution via cross-validation\")\n",
    "\n",
    "# Here, we observe a small training error (actually zero), meaning that the model is not under-fitting: \n",
    "# it is flexible enough to capture any variations present in the training set.\n",
    "\n",
    "# However the significantly larger testing error tells us that the model is over-fitting: \n",
    "# the model has memorized many variations of the training set that could be considered \"noisy\" because \n",
    "# they do not generalize to help us make good prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 ms, sys: 81 ms, total: 264 ms\n",
      "Wall time: 8.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "max_depth = [1, 5, 10, 15, 20, 25]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    param_name=\"max_depth\",\n",
    "    param_range=max_depth,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2\n",
    ")\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(\n",
    "    max_depth,\n",
    "    train_errors.mean(axis=1),\n",
    "    yerr=train_errors.std(axis=1),\n",
    "    label='Training error'\n",
    ")\n",
    "plt.errorbar(\n",
    "    max_depth,\n",
    "    test_errors.mean(axis=1),\n",
    "    yerr=test_errors.std(axis=1),\n",
    "    label='Testing error'\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Maximum depth of decision tree\")\n",
    "plt.ylabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Validation curve for decision tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What does the above validation curve reveal ?\n",
    "\n",
    "The validation curve can be divided into three areas:\n",
    "\n",
    "* For `max_depth < 10`, the decision tree is underfitting. The training error and, therefore, the testing error are both high. \n",
    "The model is too constrained and cannot capture much of the variability of the target variable.\n",
    "\n",
    "\n",
    "\n",
    "* The region around `max_depth = 10` corresponds to the parameter for which the decision tree generalizes the best. It is flexible enough to capture a fraction of the variability of the target that generalizes while not memorizing all of the noise in the target.\n",
    "\n",
    "\n",
    "* For `max_depth > 10`, the decision tree overfits. The training error becomes very small while the testing error increases. In this region, the model creates decisions specifically for noisy samples harming its ability to generalize to test data.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Note that for `max_depth = 10`, the model overfits a bit as there is a gap between the training and testing errors. Further, we can see that the variance of the errors is slight compared to their respective values.\n",
    "\n",
    "It can potentially underfit a bit at the same time because the training error is still far from zero (more than 30 k$), meaning that the model might still be too constrained to model interesting parts of the data. \n",
    "\n",
    "However, the testing error is minimal, and this is what matters and the best compromise we could reach by just tuning this parameter.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Curve\n",
    "\n",
    "To understand the impact of the number of samples available for training on the generalization performance of a predictive model, it is possible to synthetically reduce the number of samples used to train the predictive model and check the training and testing errors.\n",
    "\n",
    "We can acquire knowledge by plotting a curve called the learning curve. scikit-learn has `learning_curve` function that works with different sizes of samples.\n",
    "We will use `learning_curve` in the above experiment and vary the size of the number of samples. \n",
    "\n",
    "<br>\n",
    "\n",
    "Below we use the `learning_curve` for `DecisionTreeRegressor` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the range for size of sample data is [0.1   0.325 0.55  0.775 1.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# again loading data to keep things in one view\n",
    "# this was already loaded earlier in this notebook\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "\n",
    "\n",
    "housing = fetch_california_housing(\n",
    "    as_frame=True\n",
    ")\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "print(\n",
    "    f\"the range for size of sample data is {train_sizes}\"\n",
    ")\n",
    "\n",
    "cv = ShuffleSplit(\n",
    "    n_splits=30,\n",
    "    test_size=0.2\n",
    ")\n",
    "cv_results = learning_curve(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "train_size, train_scores, test_scores = cv_results[:3]\n",
    "# Convert the scores into errors\n",
    "train_errors, test_errors = -train_scores, -test_scores\n",
    "\n",
    "plt.errorbar(\n",
    "    train_size,\n",
    "    train_errors.mean(axis=1),\n",
    "    yerr=train_errors.std(axis=1),\n",
    "    label=\"Training error\"\n",
    ")\n",
    "plt.errorbar(\n",
    "    train_size,\n",
    "    test_errors.mean(axis=1),\n",
    "    yerr=test_errors.std(axis=1),\n",
    "    label=\"Testing error\"\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of samples in the training set\")\n",
    "plt.ylabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Learning curve for decision tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What does the above learning curve reveal? \n",
    "The trained model (i.e., decision tree) is overfitting the training data. Looking at the training error alone, we get an error of 0 k$. \n",
    "\n",
    "\n",
    "Looking at the testing error alone, we observe that the more samples added to the training set, the lower the testing error. \n",
    "\n",
    "Also, we are searching for the plateau of the testing error for which there is no benefit to adding samples anymore or assessing the potential gain of adding more samples into the training set.\n",
    "\n",
    "If we achieve a plateau and adding new samples in the training set does not reduce the testing error, we might have reached the Bayes error rate using the available model. \n",
    "\n",
    "Using a more complex model might be the only possibility to reduce the testing error further.\n",
    "\n",
    "*We can use the optimal value of `max_depth` as determined by the validation curve and get to the same conclusion, however in much obvious fashion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the range for size of sample data is [0.1   0.325 0.55  0.775 1.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# again loading data to keep things in one view\n",
    "# this was already loaded earlier in this notebook\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "housing = fetch_california_housing(\n",
    "    as_frame=True\n",
    ")\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "print(\n",
    "    f\"the range for size of sample data is {train_sizes}\"\n",
    ")\n",
    "\n",
    "cv = ShuffleSplit(\n",
    "    n_splits=30,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "cv_results = learning_curve(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "train_size, train_scores, test_scores = cv_results[:3]\n",
    "# Convert the scores into errors\n",
    "train_errors, test_errors = -train_scores, -test_scores\n",
    "\n",
    "plt.errorbar(\n",
    "    train_size,\n",
    "    train_errors.mean(axis=1),\n",
    "    yerr=train_errors.std(axis=1),\n",
    "    label=\"Training error\"\n",
    ")\n",
    "plt.errorbar(\n",
    "    train_size,\n",
    "    test_errors.mean(axis=1),\n",
    "    yerr=test_errors.std(axis=1),\n",
    "    label=\"Testing error\"\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of samples in the training set\")\n",
    "plt.ylabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Learning curve for decision tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ 2\n",
    "\n",
    "**1. A model is overfitting when:**\n",
    "\n",
    "a) both the train and test errors are high\n",
    "\n",
    "b) train error is low but test error is high\n",
    "\n",
    "c) train error is high but the test error is low \n",
    "\n",
    "d) both train and test errors are low\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Assuming that we have a dataset with little noise, a model is underfitting when:**\n",
    "\n",
    "a) both the train and test errors are high \n",
    "\n",
    "b) train error is low but test error is high \n",
    "\n",
    "c) train error is high but the test error is low \n",
    "\n",
    "d) both train and test errors are low\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. For a fixed training set, by sequentially adding parameters to give more flexibility to the model, we are more likely to observe:**\n",
    "\n",
    "a) a wider difference between train and test errors\n",
    "\n",
    "b) a reduction in the difference between train and test errors\n",
    "\n",
    "c) an increased or steady train error\n",
    "\n",
    "d) a decrease in the train error \n",
    "\n",
    "<br>\n",
    "\n",
    "**4. For a fixed choice of model parameters, if we increase the number of labeled observations in the training set, are we more likely to observe:**\n",
    "\n",
    "a) a wider difference between train and test errors\n",
    " \n",
    "b) a reduction in the difference between train and test errors\n",
    " \n",
    "c) an increased or steady train error\n",
    " \n",
    "d) a decrease in the train error\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Polynomial models with a high degree parameter:**\n",
    "\n",
    "a) always have the best test error (but can be slow to train)\n",
    "\n",
    "b) underfit more than linear regression models\n",
    "\n",
    "c) get lower training error than lower degree polynomial models\n",
    "\n",
    "d) are more likely to overfit than lower degree polynomial models\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**6. If we chose the parameters of a model to get the best overfitting/underfitting tradeoff, we will always get a zero test error.**\n",
    "\n",
    "a) True\n",
    "\n",
    "b) False\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias and Variance\n",
    "\n",
    "This section will try to relate the statistical concept of bias and variance to the machine learning concept of Underfitting and Overfitting. \n",
    "\n",
    "We will see that they are synonymous. \n",
    "\n",
    "Before we go further, let's put words to the bias-variance tradeoff. \n",
    "\n",
    "<br>\n",
    "\n",
    "In statistics and machine learning, the bias-variance tradeoff is the property of a model - increasing the bias in the estimated parameters can reduce the variance of the parameter estimated across samples.\n",
    "\n",
    "The bias-variance dilemma or bias-variance problem is the conflict in simultaneously minimizing these two sources of error, i.e., bias and variance, preventing supervised learning algorithms from generalizing beyond their training set.\n",
    "\n",
    "* The bias error is an error from erroneous assumptions in the learning algorithm. \\\n",
    "High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
    "\n",
    "* The variance is an error from sensitivity to small fluctuations in the training set. \\\n",
    "A high variance may result from an algorithm modeling the random noise in the training data (overfitting).\n",
    "\n",
    "The bias-variance decomposition analyzes a learning algorithm's expected generalization error concerning a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, i.e., $\\epsilon$, resulting from noise in the problem itself.\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)\n",
    "\n",
    "When we work in machine learning on training data, we have access to a limited number of observations to build our training set. And this comes from the fact that it's usually costly to collect the data points and label the value of the target variable for each of those data points. \n",
    "\n",
    "Usually, the specific training set we have to train the model is small. Further, it is a random subset of all the possible observations for the phenomenon we are trying to model. \n",
    "\n",
    "Suppose we pick the example of the model that predicts the income level based on demographic data. In that case, we have access to a survey of a couple of thousands of people from whom we collect the data. And we hope that by training a model on this survey data, we can generalize to the general population of the United States, where we have hundreds of millions of people. \n",
    "\n",
    "So, we have small training sets. We try to make predictions for all the possible observations. But those tens of thousands of data points are taken at random in the general population in the US. \n",
    "\n",
    "How would our model change if had access to a different subset, not the one we observed?\n",
    "\n",
    "What is the impact of this choice of the training set on the learned prediction function?\n",
    "\n",
    "Say we have a model where we try to predict Y on an X-Y axis from the X-axis. \n",
    "And there is a ground truth model that we do not have access to, f*, plus some noise that this data generates.\n",
    "\n",
    "***\n",
    "\n",
    "**Overfit/Variance** \n",
    "\n",
    "Consider we have access to just 30 data points for our training. Suppose we fit our degree 9 polynomial on this. In that case, you see that we have this overfitting model with those extreme predictions on the edges. We can represent this model as a blue arrow on a target. \n",
    "\n",
    "Ideally, the best model would be in the center. \n",
    "\n",
    "So the f* model here would be in the center and have zero prediction errors. \n",
    "\n",
    "And this model is making some prediction errors on the edges in a different manner, left and right. \n",
    "\n",
    "And suppose we get access to a different training set for the same problem. In that case, we will get a different model and thus make very different predictions on the edges and a very different location on the target. But errors from the center, i.e., the distance to the center (or the prediction error), will be approximately the same as the previous one. This one is not necessarily better than this one. They are just different. And if we resample this data set many times, we get many different functions. \n",
    "\n",
    "We see that is overfitting as it is trying to go through the specific data points and capture the noise and is not related to the general shape of the generative process.\n",
    "\n",
    "So if we repeat this many times, we get plenty of models that are very different from one another. But you see that the kind of errors that they make are not necessarily the same. \n",
    "\n",
    "![no order at all](../figures/variance.png)\n",
    "\n",
    "Suppose we repeat the process with a different set of training. We will have under-prediction and over-prediction errors, but we will not make systematic errors. \n",
    "\n",
    "![overfit variance](../figures/variance_4.png)\n",
    "\n",
    "So the average model would probably be good. But the individual models that we get by training on different training sets are very different from one another. They are all bad. \n",
    "\n",
    "And they are all overfitting. So this problem is what we call the variance of the estimated model, which is a significant dependency on slight variations of the training set. \n",
    "\n",
    "***\n",
    "\n",
    "**Underfit/Bias**\n",
    "\n",
    "On the other side of the spectrum, we have another problem, which is the problem of bias. \n",
    "\n",
    "We fit another family of models on the same data, just linear models, straight lines, or degree 1 polynomial. \n",
    "\n",
    "And we can see that this model is making some prediction errors. And because we are making some prediction errors, the model is not located at the center of the target because we have some test errors. \n",
    "\n",
    "If we change the training set sample again, we see that the function does not move much this time. So the prediction function is not impacted much. \n",
    "\n",
    "You see, on the target, it doesn't move much. And here, the slope is almost the same. \n",
    "\n",
    "And we can do another one here. \n",
    "\n",
    "![some order](../figures/bias.png)\n",
    "\n",
    "If we repeat this many times, all the models make some errors. \n",
    "\n",
    "But what is interesting here is that the errors are groups. They make the same kind of errors. In particular, here, you see that they all underpredict those values. \n",
    "\n",
    "![underfit bias](../figures/bias_4.png)\n",
    "\n",
    "In this region in the center, they over-predict all of them. None of them can predict a small value here. And here again, we have under predictions. So on the target, those models suffer from a bias that moves them away from the center on average. \n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "To summarize underfit versus overfit, or bias versus variance, the bias is that all the models make a systematic prediction error. And so, on average, they are not good. \n",
    "\n",
    "Whereas the variance is that maybe on average, they are good, they are centered around the optimal model. Still, they have a high sensitivity to the specific training set that we have used to estimate those models. \n",
    "\n",
    "And therefore, they also have lousy test errors.\n",
    "\n",
    "![bias and variance](../figures/b_vs_v.png)\n",
    "\n",
    "\n",
    "**Important Note**\n",
    "\n",
    "![bias vs bias](../figures/bias_vs_bias.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "[source](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intutive explanation of Bias and Variance and easy proof without $\\varepsilon$\n",
    "\n",
    "Below is another intuitive visual representation of Bais and variance.\n",
    "\n",
    "![bias and variance](../figures/easy_bias_variance.png)\n",
    "\n",
    "$\\hat{\\theta}$ is the point estimation of the predicted target or prediction of a given model fit with a certain training set\n",
    "\n",
    "$\\operatorname{E}$ is the Expectation over the training sets ( training sets drawn from the same distribution of the population )\n",
    "\n",
    "$\\operatorname{E}[\\hat{\\theta}]$ is the average of the prediction of a given data in the test set.  \n",
    "\n",
    "Different arrow paths are different models trained on different training sets from the same population distribution.\n",
    "\n",
    "Where the arrow hit is the prediction for a given data point, and the target is the \"true target\" value for the given data point.\n",
    "\n",
    "The goal of the model is to predict this target value or hit this target value. \n",
    "\n",
    "![variance](../figures/easy_variance.png)\n",
    "\n",
    "Intutivly the  $\\operatorname{MSE}$ will be $\\left[(\\hat{\\theta}-\\theta)^2\\right]$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**ML representation of the same concept**\n",
    "\n",
    "$ y = f(x) $ is the true target \n",
    "\n",
    "<br>\n",
    "\n",
    "$\\hat{y} = \\hat{f}(x) = h(x)$ is the prediction \n",
    "\n",
    "<br>\n",
    "\n",
    "$ S = (y - \\hat{y})^{2}$ is the squared error \n",
    "\n",
    "<br>\n",
    "\n",
    "and $\\operatorname{MSE}$ will be equal to the Expectation of $S$, i.e., Average of $S$\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{MSE} = \\operatorname{E}[S] = \\operatorname{E}(y - \\hat{y})^{2}$\n",
    "\n",
    "<br>\n",
    "\n",
    "To reiterate the Expectation is over the training data, i.e., the average estimator from different training samples\n",
    "\n",
    "<br>\n",
    "\n",
    "$ S = (y - \\hat{y})^{2} = (y - \\operatorname{E}[\\hat{y}] +  \\operatorname{E}[\\hat{y}]  + \\hat{y})^{2}$\n",
    "\n",
    "\n",
    "$\\qquad\\qquad\\qquad = (y - \\operatorname{E}[\\hat{y}])^{2} +  (\\operatorname{E}[\\hat{y}] - \\hat{y})^{2}  - 2(y - \\operatorname{E}[\\hat{y}])(\\operatorname{E}[\\hat{y}] - \\hat{y})$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Now we will apply the Expecation to each term in equation of form $a^{2} + b^{2} -2ab$ to deduce $\\operatorname{MSE}$\n",
    "\n",
    "\n",
    "$ \\operatorname{E}[S] = \\operatorname{E}[(y - \\hat{y})^{2}] = \\operatorname{E}\\left[(y - \\operatorname{E}[\\hat{y}])^{2} +  (\\operatorname{E}[\\hat{y}] - \\hat{y})^{2}  - 2(y - \\operatorname{E}[\\hat{y}])(\\operatorname{E}[\\hat{y}] - \\hat{y})\\right] $\n",
    "\n",
    "<br>\n",
    "\n",
    "Note that $(y - \\operatorname{E}[\\hat{y}])$ is constant term, so average or expecation doesnt change anything.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{E}\\left[2(y - \\operatorname{E}[\\hat{y}])(\\operatorname{E}[\\hat{y}] - \\hat{y})\\right] \\quad = 2\\operatorname{E}\\left[(y - \\operatorname{E}[\\hat{y}])(\\operatorname{E}[\\hat{y}] - \\hat{y})\\right]$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad = 2(y - \\operatorname{E}[\\hat{y}])\\operatorname{E}\\left[(\\operatorname{E}[\\hat{y}] - \\hat{y})\\right]$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad = 2(y - \\operatorname{E}[\\hat{y}]) (\\operatorname{E}[\\operatorname{E}[\\hat{y}]] - \\operatorname{E}[\\hat{y}])$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad = 2(y - \\operatorname{E}[\\hat{y}]) (\\operatorname{E}[\\hat{y}] - \\operatorname{E}[\\hat{y}])$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad = 0$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{E}(y - \\hat{y})^{2} = (y - \\operatorname{E}[\\hat{y}])^{2} + \\operatorname{E} \\left [(\\operatorname{E}[\\hat{y}] - \\hat{y})\\right]$\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{E}(y - \\hat{y})^{2} = \\operatorname{Bias}^{2} + \\operatorname{Var}$\n",
    "\n",
    "<br>\n",
    "\n",
    "An awesome resource to understand bias and variance [MLU-explains](https://mlu-explain.github.io/bias-variance/)\n",
    "\n",
    "\n",
    "\n",
    "[source](https://youtu.be/r25dWiyDPQA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bias, Variance and MSE - with error terms\n",
    "\n",
    "*** \n",
    "\n",
    "The MSE of an estimator $\\hat{\\theta}$ with respect to an unknown parameter $\\theta$ is defined as:\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{MSE}(\\hat{\\theta})=\\operatorname{E}_{\\theta}\\left[(\\hat{\\theta}-\\theta)^2\\right]$\n",
    "\n",
    "<br>\n",
    "\n",
    "*\"the estimator is the method selected to obtain an estimate of an unknown parameter\"*\n",
    "\n",
    "This definition depends on the unknown parameter, but the MSE is ''a priori'' a property of an estimator. \n",
    "\n",
    "The MSE could be a function of unknown parameters, in which case any ''estimator'' of the MSE based on estimates of these parameters would be a function of the data (and thus a random variable). \n",
    "\n",
    "*If the estimator $\\hat{\\theta}$ is derived as a sample statistic and is used to estimate some population parameter, then the expectation is with respect to the sampling distribution of the sample statistic.*\n",
    "\n",
    "The MSE can be written as the sum of the $\\operatorname{Var}$ of the estimator and the squared $\\operatorname{Bias}$ of the estimator, providing a useful way to calculate the MSE and implying that in the case of unbiased estimators, the $\\operatorname{MSE}$ and variance are equivalent.\n",
    "\n",
    "$\\operatorname{MSE}(\\hat{\\theta})=\\operatorname{Var}_{\\theta}(\\hat{\\theta})+ \\operatorname{Bias}(\\hat{\\theta},\\theta)^2$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Derivation**\n",
    "\n",
    "$\\operatorname{MSE}(\\hat{\\theta}) = \\operatorname{E}_{\\theta} \\left [(\\hat{\\theta}-\\theta)^2 \\right ]$\n",
    "\n",
    "$\\qquad\\qquad  = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta} [\\hat\\theta]+\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right)^2\\right]$ \n",
    "\n",
    "$\\qquad\\qquad = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta]\\right)^2 +2\\left (\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta] \\right ) \\left (\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta \\right )+\\left( \\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta \\right)^2\\right] $\n",
    "\n",
    "$\\qquad\\qquad  = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta]\\right)^2\\right]+\\operatorname{E}_{\\theta}\\left[2 \\left (\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta] \\right ) \\left (\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta \\right ) \\right] + \\operatorname{E}_{\\theta}\\left [ \\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right)^2 \\right]$\n",
    "\n",
    "$\\qquad\\qquad  = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta]\\right)^2\\right]+ 2 \\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right) \\operatorname{E}_{\\theta}\\left[\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta] \\right] +  \\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right)^2 \\qquad\\qquad \\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta = \\text{const.}$\n",
    "\n",
    "$\\qquad\\qquad = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta]\\right)^2\\right]+ 2 \\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right) \\left ( \\operatorname{E}_{\\theta}[\\hat{\\theta}]-\\operatorname{E}_{\\theta}[\\hat\\theta] \\right )+ \\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right)^2 \\qquad\\qquad \\operatorname{E}_{\\theta}[\\hat\\theta] = \\text{const.}$\n",
    "\n",
    "$\\qquad\\qquad  = \\operatorname{E}_{\\theta}\\left[\\left(\\hat{\\theta}-\\operatorname{E}_{\\theta}[\\hat\\theta]\\right)^2\\right]+\\left(\\operatorname{E}_{\\theta}[\\hat\\theta]-\\theta\\right)^2$\n",
    "\n",
    "$\\qquad\\qquad  = \\operatorname{Var}_{\\theta}(\\hat\\theta)+ \\operatorname{Bias}_{\\theta}(\\hat\\theta,\\theta)^2$\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "Suppose that we have a training set consisting of a set of points $x_1, \\dots, x_n$ and real values $y_i$ associated with each point $x_i$. \n",
    "\n",
    "We assume that there is a function with noise $y = f(x) + \\varepsilon$, where the noise, $varepsilon$, has zero mean and variance $\\sigma^2$.\n",
    "\n",
    "We want to find a function $\\hat{f}(x;D)$, that approximates the true function $f(x)$ \"as well as possible\", \\\n",
    "by means of some learning algorithm based on a training dataset (sample) $D=\\{(x_1,y_1) \\dots, (x_n, y_n)\\}$. \n",
    "\n",
    "We make \"as well as possible\" precise by measuring the mean squared error between $y$ and $\\hat{f}(x;D)$:\\\n",
    "we want $(y - \\hat{f}(x;D))^2$ to be minimal, both for $x_1, \\dots, x_n$ and *for points outside of our sample*. \n",
    "\n",
    "Of course, we cannot hope to do so perfectly, since the $y_i$ contain noise $\\varepsilon$; \n",
    "\n",
    "this means we must be prepared to accept an *irreducible error* in any function we come up with.\n",
    "\n",
    "\n",
    "Finding an $\\hat{f}$ that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning.\\\n",
    "As shown whichever function $\\hat{f}$ we select, we can decompose its expected  error on an unseen sample $x$ as follows\n",
    "\n",
    "\n",
    "$\\operatorname{E}_{D, \\varepsilon} \\Big[\\big(y - \\hat{f}(x;D)\\big)^2\\Big] = \\Big(\\operatorname{Bias}_D\\big[\\hat{f}(x;D)\\big] \\Big) ^2 + \\operatorname{Var}_D\\big[\\hat{f}(x;D)\\big] + \\sigma^2$\n",
    "\n",
    "where \n",
    "<br>\n",
    "\n",
    "$\\operatorname{Bias}_D\\big[\\hat{f}(x;D)\\big] = \\operatorname{E}_D\\big[\\hat{f}(x;D)\\big] - f(x)$\n",
    "\n",
    "and \n",
    "<br>\n",
    "\n",
    "$\\operatorname{Var}_D\\big[\\hat{f}(x;D)\\big] = \\operatorname{E}_D[\\big(\\operatorname{E}_D[\\hat{f}(x;D)] - \\hat{f}(x;D)\\big)^2].$\n",
    "\n",
    "<br>\n",
    "\n",
    "For notational convenience, we abbreviate $f = f(x)$, $\\hat{f} = \\hat{f}(x;D)$ and we drop the $D$ subscript on our expectation operators.\n",
    "\n",
    "<br>\n",
    "\n",
    "First, recall that, by definition, for any random variable $X$, we have\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{Var}[X] = \\operatorname{E}[X^2] - \\operatorname{E}[X]^2.$\n",
    "\n",
    "<br>\n",
    "\n",
    "Rearranging, we get:\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{E}[X^2] = \\operatorname{Var}[X] + \\operatorname{E}[X]^2.$\n",
    "\n",
    "<br>\n",
    "\n",
    "Since $f$ is deterministic, i.e. independent of $D$,\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\operatorname{E}[f] = f$\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus, given $y = f + \\varepsilon$ and $\\operatorname{E}[\\varepsilon] = 0$ \n",
    "\n",
    "<br>\n",
    "\n",
    "(because $\\varepsilon$ is noise), implies $\\operatorname{E}[y] = \\operatorname{E}[f + \\varepsilon] = \\operatorname{E}[f] = f.$\n",
    "\n",
    "<br>\n",
    "\n",
    "Also, since $\\operatorname{Var}[\\varepsilon] = \\sigma^2,$\n",
    "\n",
    "<br>\n",
    "\n",
    "$ \\operatorname{Var}[y] = \\operatorname{E}[(y - \\operatorname{E}[y])^2] = \\operatorname{E}[(y - f)^2] = \\operatorname{E}[(f + \\varepsilon - f)^2] = \\operatorname{E}[\\varepsilon^2] = \\operatorname{Var}[\\varepsilon] + \\operatorname{E}[\\varepsilon]^2  = \\sigma^2 + 0^2 = \\sigma^2.$\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus, since $\\varepsilon$ and $\\hat{f}$ are independent, we can write\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\begin{align}\n",
    "\\operatorname{E}\\big[(y - \\hat{f})^2\\big]\n",
    " & = \\operatorname{E}\\big[(f+\\varepsilon  - \\hat{f} )^2\\big] \\\\[5pt]\n",
    " & = \\operatorname{E}\\big[(f+\\varepsilon  - \\hat{f} +\\operatorname{E}[\\hat{f}]-\\operatorname{E}[\\hat{f}])^2\\big] \\\\[5pt]\n",
    " & = \\operatorname{E}\\big[(f-\\operatorname{E}[\\hat{f}])^2\\big]+\\operatorname{E}[\\varepsilon^2]+\\operatorname{E}\\big[(\\operatorname{E}[\\hat{f}]- \\hat{f})^2\\big] \n",
    "+2\\operatorname{E}\\big[(f-\\operatorname{E}[\\hat{f}])\\varepsilon\\big]\n",
    "+2\\operatorname{E}\\big[\\varepsilon(\\operatorname{E}[\\hat{f}]- \\hat{f})\\big]\n",
    "+2\\operatorname{E}\\big[(\\operatorname{E}[\\hat{f}]- \\hat{f})(f-\\operatorname{E}[\\hat{f}])\\big] \\\\[5pt]\n",
    " & = (f-\\operatorname{E}[\\hat{f}])^2+\\operatorname{E}[\\varepsilon^2]+\\operatorname{E}\\big[(\\operatorname{E}[\\hat{f}]- \\hat{f})^2\\big] \n",
    "+2(f-\\operatorname{E}[\\hat{f}])\\operatorname{E}[\\varepsilon]\n",
    "+2\\operatorname{E}[\\varepsilon]\\operatorname{E}\\big[\\operatorname{E}[\\hat{f}]- \\hat{f}\\big]\n",
    "+2\\operatorname{E}\\big[\\operatorname{E}[\\hat{f}]- \\hat{f}\\big](f-\\operatorname{E}[\\hat{f}]) \\\\[5pt]\n",
    " & = (f-\\operatorname{E}[\\hat{f}])^2+\\operatorname{E}[\\varepsilon^2]+\\operatorname{E}\\big[(\\operatorname{E}[\\hat{f}]- \\hat{f})^2\\big]\\\\[5pt]\n",
    " & = (f-\\operatorname{E}[\\hat{f}])^2+\\operatorname{Var}[\\varepsilon]+\\operatorname{Var}\\big[\\hat{f}\\big]\\\\[5pt]\n",
    " & = \\operatorname{Bias}[\\hat{f}]^2+\\operatorname{Var}[\\varepsilon]+\\operatorname{Var}\\big[\\hat{f}\\big]\\\\[5pt]\n",
    " & = \\operatorname{Bias}[\\hat{f}]^2+\\sigma^2+\\operatorname{Var}\\big[\\hat{f}\\big].\n",
    "\\end{align}$\n",
    "\n",
    "<br>\n",
    "\n",
    "Finally, MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over $x\\sim P$ : \n",
    "\n",
    "<br>\n",
    "\n",
    "$ \\text{MSE} = \\operatorname{E}_x\\bigg\\{\\operatorname{Bias}_D[\\hat{f}(x;D)]^2+\\operatorname{Var}_D\\big[\\hat{f}(x;D)\\big]\\bigg\\} + \\sigma^2. $\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff#Bias%E2%80%93variance_decomposition_of_mean_squared_error)\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ 3\n",
    "\n",
    "**1. what kind of bias and variance below image represent?**\n",
    "\n",
    "![1](../figures/q3_1.png)\n",
    "\n",
    "a) low bias\n",
    "\n",
    "b) low variance\n",
    "\n",
    "c) high bias\n",
    "\n",
    "d) high variance \n",
    "\n",
    "<br>\n",
    "\n",
    "**2. what kind of bias and variance below image represent?**\n",
    "\n",
    "![2](../figures/q3_2.png)\n",
    "\n",
    "a) low bias\n",
    "\n",
    "b) low variance\n",
    "\n",
    "c) high bias\n",
    "\n",
    "d) high variance \n",
    "\n",
    "<br>\n",
    "\n",
    "**3. what kind of bias and variance below image represent?**\n",
    "\n",
    "![3](../figures/q3_3.png)\n",
    "\n",
    "a) low bias\n",
    "\n",
    "b) low variance\n",
    "\n",
    "c) high bias\n",
    "\n",
    "d) high variance \n",
    "\n",
    "<br>\n",
    "\n",
    "**4. what kind of bias and variance below image represent?**\n",
    "\n",
    "![4](../figures/q3_4.png)\n",
    "\n",
    "a) low bias\n",
    "\n",
    "b) low variance\n",
    "\n",
    "c) high bias\n",
    "\n",
    "d) high variance \n",
    "\n",
    "<br>\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Bias–variance_tradeoff)\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuning \n",
    "\n",
    "\n",
    "Learning of a predictive model is driven by a set of internal parameters and training data. These internal parameters are called hyperparameters and are specific for each family of models. \n",
    " \n",
    "*Hyperparameters are the parameters that can be used to control the learning process.*\n",
    "\n",
    "The user specifies hyperparameters, often manually tuned (or by an exhaustive automatic search), and cannot be estimated from the data. \n",
    " \n",
    "They should not be confused with the fitted parameters resulting from the training. These fitted parameters are recognizable in scikit-learn because they are spelled with a final underscore `_` for instance, `model.coef_`.\n",
    "\n",
    "Sklearn provides an easy interface to get and set the hyperparameters via `get_params` and `set_params` functions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "\n",
    "target_name = \"class\"\n",
    "numerical_columns = [\n",
    "    \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "target = adult_census[target_name]\n",
    "data = adult_census[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  capital-gain  capital-loss  hours-per-week\n",
       "0   25             0             0              40\n",
       "1   38             0             0              50\n",
       "2   28             0             0              40\n",
       "3   44          7688             0              40\n",
       "4   18             0             0              30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         <=50K\n",
       "1         <=50K\n",
       "2          >50K\n",
       "3          >50K\n",
       "4         <=50K\n",
       "          ...  \n",
       "48837     <=50K\n",
       "48838      >50K\n",
       "48839     <=50K\n",
       "48840     <=50K\n",
       "48841      >50K\n",
       "Name: class, Length: 48842, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score via cross-validation:\n",
      "0.800 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", StandardScaler()),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(model, data, target)\n",
    "scores = cv_results[\"test_score\"]\n",
    "print(\n",
    "    f\"Accuracy score via cross-validation:\\n\"\n",
    "    f\"{scores.mean():.3f} +/- {scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "preprocessor\n",
      "classifier\n",
      "preprocessor__copy\n",
      "preprocessor__with_mean\n",
      "preprocessor__with_std\n",
      "classifier__C\n",
      "classifier__class_weight\n",
      "classifier__dual\n",
      "classifier__fit_intercept\n",
      "classifier__intercept_scaling\n",
      "classifier__l1_ratio\n",
      "classifier__max_iter\n",
      "classifier__multi_class\n",
      "classifier__n_jobs\n",
      "classifier__penalty\n",
      "classifier__random_state\n",
      "classifier__solver\n",
      "classifier__tol\n",
      "classifier__verbose\n",
      "classifier__warm_start\n"
     ]
    }
   ],
   "source": [
    "# as you can see that the name we gave to the pipeline steps\n",
    "# is appended to the hyperparameters name so that one can easily identify them\n",
    "# also notice the double underscores i.e. __\n",
    "for parameter in model.get_params():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the hyperparameter used the default value of C as 1\n",
    "model.get_params()['classifier__C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail 1 accuracy score via cross-validation with C=0.001:\n",
      "0.787 +/- 0.002\n",
      "Trail 2 accuracy score via cross-validation with C=0.01:\n",
      "0.799 +/- 0.003\n",
      "Trail 3 accuracy score via cross-validation with C=0.1:\n",
      "0.800 +/- 0.003\n",
      "Trail 4 accuracy score via cross-validation with C=1:\n",
      "0.800 +/- 0.003\n",
      "Trail 5 accuracy score via cross-validation with C=10:\n",
      "0.800 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "# now we can use the set_param function to systamtically\n",
    "#  change the  value of the hyperparameters \n",
    "for index, C in enumerate([1e-3, 1e-2, 1e-1, 1, 10]):\n",
    "    model.set_params(\n",
    "        classifier__C=C\n",
    "    )\n",
    "    cv_results = cross_validate(model, data, target)\n",
    "    scores = cv_results[\"test_score\"]\n",
    "    print(f\"Trail {index+1} accuracy score via cross-validation with C={C}:\\n\"\n",
    "          f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with Grid-Search\n",
    "\n",
    "\n",
    "We used one for loop for each hyperparameter to find the best combination over a fixed grid of values. \n",
    "\n",
    "`GridSearchCV` is a scikit-learn class that implements a similar logic with less repetitive code but is just as costly or time-consuming as using for loops.\n",
    "\n",
    "The `GridSearchCV` estimator takes a `param_grid` parameter which defines all hyperparameters and their associated values. \n",
    "\n",
    "The `GridSearchCV` will be in charge of creating all possible combinations and testing them.\n",
    "\n",
    "The number of combinations will be equal to the product of the number of values to explore for each parameter (e.g., in our example it will be 4 x 3 combinations). \n",
    "\n",
    "Thus, adding new parameters with their associated values to be explored has become rapidly computationally expensive.\n",
    "\n",
    "*The best combination is selected by keeping the combination leading to the best mean cross-validated score.*\n",
    "\n",
    "Once the grid-search is fitted, it can be used as any other predictor by calling `predict` and `predict_proba`. \n",
    "\n",
    "**Internally, it will use the model with the best parameters found during `fit`.**\n",
    "\n",
    "<br>\n",
    "\n",
    "Remember that `GridSearchCV` uses a cross-validate approach and accepts a `cv` flag.\n",
    "\n",
    "<code>\n",
    "cv : int, cross-validation generator or an iterable, default=None\n",
    "\n",
    "Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "- None, to use the default 5-fold cross-validation,\n",
    "\n",
    "- integer, to specify the number of folds in a (Stratified)KFold,\n",
    "\n",
    "- CV splitter,\n",
    "\n",
    "- An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "\n",
    "In all other cases, KFold is used. These splitters are instantiated with shuffle=False, so the splits will be the same across calls.\n",
    "\n",
    "</code>\n",
    "\n",
    "<br>\n",
    "\n",
    "We will use a tree-based model as a classifier (i.e. `HistGradientBoostingClassifier`) along with `GridSearchCV`\n",
    "\n",
    "That means:\n",
    "* Numerical variables don't need scaling;\n",
    "* Categorical variables can be dealt with by an OrdinalEncoder even if the coding order is not meaningful;\n",
    "* For tree-based models, the OrdinalEncoder avoids having high-dimensional representations.\n",
    "\n",
    "<br>\n",
    "\n",
    "[source](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn-model-selection-gridsearchcv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education       marital-status          occupation  \\\n",
       "0   25     Private           11th        Never-married   Machine-op-inspct   \n",
       "1   38     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   28   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3   44     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4   18           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0    Own-child   Black     Male             0             0              40   \n",
       "1      Husband   White     Male             0             0              50   \n",
       "2      Husband   White     Male             0             0              40   \n",
       "3      Husband   Black     Male          7688             0              40   \n",
       "4    Own-child   White   Female             0             0              30   \n",
       "\n",
       "   native-country  \n",
       "0   United-States  \n",
       "1   United-States  \n",
       "2   United-States  \n",
       "3   United-States  \n",
       "4   United-States  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                  transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                 OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;native-country&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_preprocessor</label><div class=\"sk-toggleable__content\"><pre>[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_leaf_nodes=4, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
       "                                   transformers=[('cat_preprocessor',\n",
       "                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  ['workclass', 'education',\n",
       "                                                   'marital-status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'native-country'])])),\n",
       "                ('classifier',\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('cat_preprocessor', categorical_preprocessor, categorical_columns)],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\",HistGradientBoostingClassifier(random_state=42, max_leaf_nodes=4))\n",
    "    ]\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: user 11.8 s, sys: 7.64 s, total: 19.4 s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          sparse_threshold=0,\n",
       "                                                          transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                                         OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                        unknown_value=-1),\n",
       "                                                                         [&#x27;workclass&#x27;,\n",
       "                                                                          &#x27;education&#x27;,\n",
       "                                                                          &#x27;marital-status&#x27;,\n",
       "                                                                          &#x27;occupation&#x27;,\n",
       "                                                                          &#x27;relationship&#x27;,\n",
       "                                                                          &#x27;race&#x27;,\n",
       "                                                                          &#x27;sex&#x27;,\n",
       "                                                                          &#x27;native-country&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                                       random_state=42))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: (0.01, 0.1, 1, 10),\n",
       "                         &#x27;classifier__max_leaf_nodes&#x27;: (3, 10, 30)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          sparse_threshold=0,\n",
       "                                                          transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                                         OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                        unknown_value=-1),\n",
       "                                                                         [&#x27;workclass&#x27;,\n",
       "                                                                          &#x27;education&#x27;,\n",
       "                                                                          &#x27;marital-status&#x27;,\n",
       "                                                                          &#x27;occupation&#x27;,\n",
       "                                                                          &#x27;relationship&#x27;,\n",
       "                                                                          &#x27;race&#x27;,\n",
       "                                                                          &#x27;sex&#x27;,\n",
       "                                                                          &#x27;native-country&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                                       random_state=42))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: (0.01, 0.1, 1, 10),\n",
       "                         &#x27;classifier__max_leaf_nodes&#x27;: (3, 10, 30)},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                  transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                 OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;native-country&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_preprocessor</label><div class=\"sk-toggleable__content\"><pre>[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_leaf_nodes=4, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          sparse_threshold=0,\n",
       "                                                          transformers=[('cat_preprocessor',\n",
       "                                                                         OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                        unknown_value=-1),\n",
       "                                                                         ['workclass',\n",
       "                                                                          'education',\n",
       "                                                                          'marital-status',\n",
       "                                                                          'occupation',\n",
       "                                                                          'relationship',\n",
       "                                                                          'race',\n",
       "                                                                          'sex',\n",
       "                                                                          'native-country'])])),\n",
       "                                       ('classifier',\n",
       "                                        HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                                       random_state=42))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'classifier__learning_rate': (0.01, 0.1, 1, 10),\n",
       "                         'classifier__max_leaf_nodes': (3, 10, 30)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'classifier__max_leaf_nodes': (3, 10, 30)\n",
    "}\n",
    "model_grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=2,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "model_grid_search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score of the grid-searched pipeline is: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = model_grid_search.score(\n",
    "    data_test,\n",
    "    target_test\n",
    ")\n",
    "print(\n",
    "    f\"The test accuracy score of the grid-searched pipeline is: \"\n",
    "    f\"{accuracy:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for the 5 first samples using the estimator with the best parameters.\n",
    "model_grid_search.predict(data_test.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is: {'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n"
     ]
    }
   ],
   "source": [
    "# we can know about these parameters by looking at the best_params_ attribute.\n",
    "print(\n",
    "    f\"The best set of parameters is: \"\n",
    "    f\"{model_grid_search.best_params_}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_leaf_nodes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.551062</td>\n",
       "      <td>0.096290</td>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
       "      <td>0.869387</td>\n",
       "      <td>0.872099</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.870734</td>\n",
       "      <td>0.871011</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.485611</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.050617</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
       "      <td>0.865702</td>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.870325</td>\n",
       "      <td>0.864182</td>\n",
       "      <td>0.870188</td>\n",
       "      <td>0.868445</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.272189</td>\n",
       "      <td>0.071677</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.861744</td>\n",
       "      <td>0.868550</td>\n",
       "      <td>0.865001</td>\n",
       "      <td>0.858449</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>0.863449</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281999</td>\n",
       "      <td>0.110897</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.865566</td>\n",
       "      <td>0.860087</td>\n",
       "      <td>0.868550</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>0.848621</td>\n",
       "      <td>0.861047</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.456991</td>\n",
       "      <td>0.141987</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.859697</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>0.864728</td>\n",
       "      <td>0.853399</td>\n",
       "      <td>0.859814</td>\n",
       "      <td>0.858753</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5       3.551062      0.096290         0.041365        0.005490   \n",
       "4       1.485611      0.116601         0.050617        0.006075   \n",
       "7       0.272189      0.071677         0.022422        0.001762   \n",
       "6       0.281999      0.110897         0.029666        0.007900   \n",
       "8       0.456991      0.141987         0.022252        0.001763   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_leaf_nodes  \\\n",
       "5                             0.1                               30   \n",
       "4                             0.1                               10   \n",
       "7                               1                               10   \n",
       "6                               1                                3   \n",
       "8                               1                               30   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'classifier__learning_rate': 0.1, 'classifier...           0.869387   \n",
       "4  {'classifier__learning_rate': 0.1, 'classifier...           0.865702   \n",
       "7  {'classifier__learning_rate': 1, 'classifier__...           0.861744   \n",
       "6  {'classifier__learning_rate': 1, 'classifier__...           0.865566   \n",
       "8  {'classifier__learning_rate': 1, 'classifier__...           0.859697   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.872099           0.873464           0.869369           0.870734   \n",
       "4           0.871826           0.870325           0.864182           0.870188   \n",
       "7           0.868550           0.865001           0.858449           0.863500   \n",
       "6           0.860087           0.868550           0.862408           0.848621   \n",
       "8           0.856129           0.864728           0.853399           0.859814   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.871011        0.001588                1  \n",
       "4         0.868445        0.002956                2  \n",
       "7         0.863449        0.003357                3  \n",
       "6         0.861047        0.006839                4  \n",
       "8         0.858753        0.003828                5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can inspect all results which are stored in the attribute cv_results_ of the grid-search\n",
    "cv_results = pd.DataFrame(\n",
    "    model_grid_search.cv_results_\n",
    ").sort_values(\n",
    "    \"mean_test_score\",\n",
    "    ascending=False\n",
    ")\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in results are ['param_classifier__learning_rate', 'param_classifier__max_leaf_nodes']\n",
      "updated columns in results are ['param_classifier__learning_rate', 'param_classifier__max_leaf_nodes', 'mean_test_score', 'std_test_score', 'rank_test_score']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.871011</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.868445</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.863449</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.861047</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.858753</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.854577</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0.846578</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.817996</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796675</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.264912</td>\n",
       "      <td>0.025144</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.257241</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate max_leaf_nodes  mean_test_score  std_test_score  \\\n",
       "5            0.1             30         0.871011        0.001588   \n",
       "4            0.1             10         0.868445        0.002956   \n",
       "7              1             10         0.863449        0.003357   \n",
       "6              1              3         0.861047        0.006839   \n",
       "8              1             30         0.858753        0.003828   \n",
       "3            0.1              3         0.854577        0.002054   \n",
       "2           0.01             30         0.846578        0.001669   \n",
       "1           0.01             10         0.817996        0.002148   \n",
       "0           0.01              3         0.796675        0.001855   \n",
       "9             10              3         0.283476        0.005123   \n",
       "11            10             30         0.264912        0.025144   \n",
       "10            10             10         0.257241        0.009111   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "4                 2  \n",
       "7                 3  \n",
       "6                 4  \n",
       "8                 5  \n",
       "3                 6  \n",
       "2                 7  \n",
       "1                 8  \n",
       "0                 9  \n",
       "9                10  \n",
       "11               11  \n",
       "10               12  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the parameter names\n",
    "column_results = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "print(\n",
    "    f\"columns in results are {column_results}\"\n",
    ")\n",
    "\n",
    "column_results += [\n",
    "    \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "cv_results = cv_results[column_results]\n",
    "\n",
    "print(\n",
    "    f\"updated columns in results are {column_results}\"\n",
    ")\n",
    "\n",
    "def shorten_param(param_name):\n",
    "    if \"__\" in param_name:\n",
    "        return param_name.rsplit(\"__\", 1)[1]\n",
    "    return param_name\n",
    "\n",
    "\n",
    "cv_results = cv_results.rename(shorten_param, axis=1)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pivoted_cv_results = cv_results.pivot_table(\n",
    "    values=\"mean_test_score\",\n",
    "    index=[\"learning_rate\"],\n",
    "    columns=[\"max_leaf_nodes\"]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "The below plot highlights the following things:\n",
    "\n",
    "for too high values of learning_rate, the generalization performance of the model is degraded and adjusting the value of max_leaf_nodes cannot fix that problem;\n",
    "\n",
    "outside of this pathological region, we observe that the optimal choice of max_leaf_nodes depends on the value of learning_rate;\n",
    "\n",
    "in particular, we observe a \"diagonal\" of good models with an accuracy close to the maximal of 0.87: \n",
    "when the value of max_leaf_nodes is increased, one should decrease the value of learning_rate accordingly to preserve a good accuracy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    pivoted_cv_results,\n",
    "    annot=True,\n",
    "    cmap=\"YlGnBu\",\n",
    "    vmin=0.7,\n",
    "    vmax=0.9\n",
    ")\n",
    "ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ 4\n",
    "\n",
    "Given `model` defined by ... \n",
    "\n",
    "<code>\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "</code>\n",
    "\n",
    "**1. how do you get the value of the C parameter?**\n",
    "\n",
    "a) model.get_parameters()['C'] \n",
    "\n",
    "b) model.get_params()['C'] \n",
    "\n",
    "c) model.get_params('C') \n",
    "\n",
    "d) model.get_params['C']\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. how do you set the value of the C parameter to 5?**\n",
    "\n",
    "a) model.set_params('C', 5)\n",
    "\n",
    "b) model.set_params({'C': 5})\n",
    "\n",
    "c) model.set_params()['C'] = 5\n",
    "\n",
    "d) model.set_params(C=5)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Given `model` defined by ...\n",
    "\n",
    "<code>\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "</code>\n",
    "\n",
    "**3.how do you set the value of the C parameter of the LogisticRegression component to 5?**\n",
    "\n",
    "\n",
    "a) model.set_params(C=5)\n",
    "\n",
    "b) model.set_params(logisticregression__C=5)\n",
    "\n",
    "c) model.set_params(classifier__C=5)\n",
    "\n",
    "d) model.set_params(classifier--C=5)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuning with Randomized-Search\n",
    "\n",
    "We learned to use a grid-search approach to search for the best hyperparameters to maximize a predictive model's generalization performance.\n",
    "\n",
    "However, a grid-search approach has limitations. \n",
    "\n",
    "*It does not scale when the number of tuned parameters is large.*\n",
    "\n",
    "*Also, the grid will impose a regularity during the search, which might be problematic.*\n",
    "\n",
    "*** \n",
    "\n",
    "We will learn about another method to tune hyperparameters called **randomized search**.\n",
    "\n",
    "With the `GridSearchCV` estimator, the parameters need to be specified explicitly. \n",
    "\n",
    "Instead, we can randomly generate the parameter candidates, and such an approach avoids the regularity of the grid. Hence, adding more evaluations can increase the resolution in each direction, which is the case in the frequent situation where some hyperparameters are not very important. Indeed, the number of evaluation points needs to be divided across the two different hyperparameters.\n",
    "\n",
    "With a grid, the danger is that the region of good hyperparameters falls between the grid line. This region is aligned with the grid, given that hyperparameter 2 has a weak influence. \n",
    "\n",
    "![randomize the search](../figures/grid_vs_random_search.png)\n",
    "\n",
    "Instead, a stochastic search will sample hyperparameter 1 independently from hyperparameter 2 and find the optimal region.\n",
    "\n",
    "The `RandomizedSearchCV` class allows for such a stochastic search. \n",
    "\n",
    "It is used similarly to the `GridSearchCV` but the sampling distributions need to be specified instead of the parameter values. \n",
    "\n",
    "*** \n",
    "\n",
    "\n",
    "Remeber that `RandomizedSearchCV` will use cross-validate approach, and accepts a `cv` flag.\n",
    "\n",
    "<code>\n",
    "\n",
    "cv : int, cross-validation generator or an iterable, default=None\n",
    "\n",
    "Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "- None, to use the default 5-fold cross validation,\n",
    "\n",
    "- integer, to specify the number of folds in a (Stratified)KFold,\n",
    "\n",
    "- CV splitter,\n",
    "\n",
    "- An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "\n",
    "In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.\n",
    "\n",
    "\n",
    "</code>\n",
    "\n",
    "For instance, we will draw candidates using a log-uniform distribution because we are interested in taking positive values with a natural log scaling.\n",
    "\n",
    "\n",
    "*Random search (with `RandomizedSearchCV`) is typically beneficial compared to grid search (with `GridSearchCV`) to optimize three or more hyperparameters.*\n",
    "\n",
    "[source](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html?highlight=randomizedsearchcv#sklearn-model-selection-randomizedsearchcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                  transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                 OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;native-country&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_preprocessor</label><div class=\"sk-toggleable__content\"><pre>[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_leaf_nodes=4, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
       "                                   transformers=[('cat_preprocessor',\n",
       "                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  ['workclass', 'education',\n",
       "                                                   'marital-status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'native-country'])])),\n",
       "                ('classifier',\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reloading/repeating code to keep code in same view \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
    "\n",
    "\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat_preprocessor', categorical_preprocessor, categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\n",
    "        \"classifier\",\n",
    "        HistGradientBoostingClassifier(\n",
    "            random_state=42,\n",
    "            max_leaf_nodes=4\n",
    "        )\n",
    "    ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "CPU times: user 15min 52s, sys: 10min 40s, total: 26min 33s\n",
      "Wall time: 8min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                sparse_threshold=0,\n",
       "                                                                transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                                               OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                              unknown_value=-1),\n",
       "                                                                               [&#x27;workclass&#x27;,\n",
       "                                                                                &#x27;education&#x27;,\n",
       "                                                                                &#x27;marital-status&#x27;,\n",
       "                                                                                &#x27;occupation&#x27;,\n",
       "                                                                                &#x27;relationship&#x27;,\n",
       "                                                                                &#x27;race&#x27;,\n",
       "                                                                                &#x27;sex&#x27;,\n",
       "                                                                                &#x27;native-country&#x27;])])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              Hi...\n",
       "                   param_distributions={&#x27;classifier__l2_regularization&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17fc94910&gt;,\n",
       "                                        &#x27;classifier__learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17f715960&gt;,\n",
       "                                        &#x27;classifier__max_bins&#x27;: &lt;__main__.loguniform_int object at 0x17d5cc130&gt;,\n",
       "                                        &#x27;classifier__max_leaf_nodes&#x27;: &lt;__main__.loguniform_int object at 0x17d5cd6c0&gt;,\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: &lt;__main__.loguniform_int object at 0x17d5ce290&gt;},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                sparse_threshold=0,\n",
       "                                                                transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                                               OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                              unknown_value=-1),\n",
       "                                                                               [&#x27;workclass&#x27;,\n",
       "                                                                                &#x27;education&#x27;,\n",
       "                                                                                &#x27;marital-status&#x27;,\n",
       "                                                                                &#x27;occupation&#x27;,\n",
       "                                                                                &#x27;relationship&#x27;,\n",
       "                                                                                &#x27;race&#x27;,\n",
       "                                                                                &#x27;sex&#x27;,\n",
       "                                                                                &#x27;native-country&#x27;])])),\n",
       "                                             (&#x27;classifier&#x27;,\n",
       "                                              Hi...\n",
       "                   param_distributions={&#x27;classifier__l2_regularization&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17fc94910&gt;,\n",
       "                                        &#x27;classifier__learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x17f715960&gt;,\n",
       "                                        &#x27;classifier__max_bins&#x27;: &lt;__main__.loguniform_int object at 0x17d5cc130&gt;,\n",
       "                                        &#x27;classifier__max_leaf_nodes&#x27;: &lt;__main__.loguniform_int object at 0x17d5cd6c0&gt;,\n",
       "                                        &#x27;classifier__min_samples_leaf&#x27;: &lt;__main__.loguniform_int object at 0x17d5ce290&gt;},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1),\n",
       "                                                  [&#x27;workclass&#x27;, &#x27;education&#x27;,\n",
       "                                                   &#x27;marital-status&#x27;,\n",
       "                                                   &#x27;occupation&#x27;, &#x27;relationship&#x27;,\n",
       "                                                   &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;native-country&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(max_leaf_nodes=4,\n",
       "                                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n",
       "                  transformers=[(&#x27;cat_preprocessor&#x27;,\n",
       "                                 OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;native-country&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_preprocessor</label><div class=\"sk-toggleable__content\"><pre>[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_leaf_nodes=4, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                sparse_threshold=0,\n",
       "                                                                transformers=[('cat_preprocessor',\n",
       "                                                                               OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                              unknown_value=-1),\n",
       "                                                                               ['workclass',\n",
       "                                                                                'education',\n",
       "                                                                                'marital-status',\n",
       "                                                                                'occupation',\n",
       "                                                                                'relationship',\n",
       "                                                                                'race',\n",
       "                                                                                'sex',\n",
       "                                                                                'native-country'])])),\n",
       "                                             ('classifier',\n",
       "                                              Hi...\n",
       "                   param_distributions={'classifier__l2_regularization': <scipy.stats._distn_infrastructure.rv_frozen object at 0x17fc94910>,\n",
       "                                        'classifier__learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x17f715960>,\n",
       "                                        'classifier__max_bins': <__main__.loguniform_int object at 0x17d5cc130>,\n",
       "                                        'classifier__max_leaf_nodes': <__main__.loguniform_int object at 0x17d5cd6c0>,\n",
       "                                        'classifier__min_samples_leaf': <__main__.loguniform_int object at 0x17d5ce290>},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "We will optimize 5 parameters, 2 of which are same as GridSearchCV\n",
    "\n",
    "1. l2_regularization: it corresponds to the strength of the regularization;\n",
    "\n",
    "2. min_samples_leaf: it corresponds to the minimum number of samples required in a leaf;\n",
    "\n",
    "3. max_bins: it corresponds to the maximum number of bins to construct the histograms.\n",
    "\n",
    "4. learning_rate: it corresponds to the speed at which the gradient-boosting will correct the residuals at each boosting iteration;\n",
    "\n",
    "5. max_leaf_nodes: it corresponds to the maximum number of leaves for each tree in the ensemble.\n",
    "\n",
    "\"\"\"\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__l2_regularization': loguniform(1e-6, 1e3),\n",
    "    'classifier__learning_rate': loguniform(0.001, 10),\n",
    "    'classifier__max_leaf_nodes': loguniform_int(2, 256),\n",
    "    'classifier__min_samples_leaf': loguniform_int(1, 100),\n",
    "    'classifier__max_bins': loguniform_int(2, 255),\n",
    "}\n",
    "\n",
    "model_random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    ")\n",
    "model_random_search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score of the best model is 0.88\n",
      "The best parameters are:\n",
      "{'classifier__l2_regularization': 0.0010853921397571927,\n",
      " 'classifier__learning_rate': 0.21426002022703367,\n",
      " 'classifier__max_bins': 197,\n",
      " 'classifier__max_leaf_nodes': 21,\n",
      " 'classifier__min_samples_leaf': 12}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "accuracy = model_random_search.score(\n",
    "    data_test,\n",
    "    target_test\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The test accuracy score of the best model is \"\n",
    "    f\"{accuracy:.2f}\"\n",
    ")\n",
    "\n",
    "print(\"The best parameters are:\")\n",
    "pprint(model_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_bins</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.21426</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>197</td>\n",
       "      <td>0.868881</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.034353</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "      <td>0.867134</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85.376222</td>\n",
       "      <td>1.046119</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "      <td>0.863749</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>419.755678</td>\n",
       "      <td>0.081039</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>74</td>\n",
       "      <td>0.851656</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.661611</td>\n",
       "      <td>1.525567</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>133</td>\n",
       "      <td>0.851110</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.05682</td>\n",
       "      <td>194</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0.850154</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.567792</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>217</td>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>0.847752</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>23.468346</td>\n",
       "      <td>0.059025</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>15</td>\n",
       "      <td>0.846223</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>110</td>\n",
       "      <td>59</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843411</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.94388</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.835768</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.799306</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0.831973</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>706.431107</td>\n",
       "      <td>0.102338</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.826540</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.083846</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826158</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.060409</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>0.817532</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.032619</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811471</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.974667</td>\n",
       "      <td>1.905077</td>\n",
       "      <td>232</td>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>0.810106</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.079929</td>\n",
       "      <td>0.458688</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.807649</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.553061</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>111</td>\n",
       "      <td>0.804646</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25.699866</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800633</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69.693656</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.796648</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796102</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.022834</td>\n",
       "      <td>1.583616</td>\n",
       "      <td>26</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>0.792416</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.033714</td>\n",
       "      <td>2.096348</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>0.790069</td>\n",
       "      <td>0.014681</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.788267</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066651</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.784527</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.799543</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.784308</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.037234</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.778767</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>179.671284</td>\n",
       "      <td>4.13935</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.770168</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43.170277</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>0.760449</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.154488</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>71.584263</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>461.380498</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>211</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.890083</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.896137</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.128667</td>\n",
       "      <td>3.07267</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.706722</td>\n",
       "      <td>0.057746</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040988</td>\n",
       "      <td>1.810923</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.674126</td>\n",
       "      <td>0.099133</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.423582</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.665011</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.332745</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0.539536</td>\n",
       "      <td>0.243058</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>6.957568</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>0.514673</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00034</td>\n",
       "      <td>3.557922</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.499218</td>\n",
       "      <td>0.153217</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>9.389501</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.403453</td>\n",
       "      <td>0.104518</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.132742</td>\n",
       "      <td>4.131661</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.402285</td>\n",
       "      <td>0.107952</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.624653</td>\n",
       "      <td>8.334376</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>215</td>\n",
       "      <td>0.257050</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l2_regularization learning_rate max_leaf_nodes min_samples_leaf max_bins  \\\n",
       "13          0.001085       0.21426             21               12      197   \n",
       "31          0.000011      0.034353             74                3      189   \n",
       "20         85.376222      1.046119             61                3      239   \n",
       "27        419.755678      0.081039             23                3       50   \n",
       "10          0.000011      0.058322              6               38       74   \n",
       "9           4.661611      1.525567             23               64      133   \n",
       "17          0.000146       0.05682            194               37       19   \n",
       "14          9.567792      0.016018            217               77       40   \n",
       "41         23.468346      0.059025              8               86       15   \n",
       "8              0.774      0.018426            110               59       15   \n",
       "2            3.94388      0.014364             20                4       16   \n",
       "36          0.799306      0.020091              7                1       69   \n",
       "3         706.431107      0.102338             25               25        6   \n",
       "30          0.002849      0.083846             44                9        5   \n",
       "23          0.000014      0.060409              2                1      183   \n",
       "19          0.002544      0.032619             15                4        4   \n",
       "33          0.974667      1.905077            232               31      122   \n",
       "6           0.079929      0.458688              3               21        3   \n",
       "37          3.553061      0.006534              7               55      111   \n",
       "15         25.699866        0.0276             24               47        2   \n",
       "16         69.693656      0.052259              2                1       28   \n",
       "35          0.002286      0.009357             88               39        3   \n",
       "29          0.022834      1.583616             26               48       41   \n",
       "26          0.033714      2.096348             23               72       13   \n",
       "25          0.000132      0.007867             14                8       12   \n",
       "5           0.066651      0.004321             35                2       40   \n",
       "28          7.799543      0.014373              2                1       23   \n",
       "21          0.037234      0.015846              3                6        4   \n",
       "22        179.671284       4.13935            118                1       11   \n",
       "11         43.170277      0.008893              3               48       37   \n",
       "40          0.000001      0.001107              5                3        6   \n",
       "38          0.001636      0.001527              3               17        7   \n",
       "39          0.000476      0.002385            206                5        4   \n",
       "44          3.154488      0.002488             22                9       61   \n",
       "0           0.000164      0.001542             19                1       16   \n",
       "34         71.584263        0.0037             13               10       65   \n",
       "32        461.380498      0.002946              8               16       78   \n",
       "24          0.000169      0.003049             10               35      211   \n",
       "12          0.890083      0.003799             24                8       41   \n",
       "7           5.896137      0.005574              2               82      208   \n",
       "49          0.000165       0.00243            233                1        2   \n",
       "43          0.128667       3.07267              6                1       51   \n",
       "18          0.040988      1.810923              7               16        4   \n",
       "48          0.000002      1.423582              2               41        9   \n",
       "46          0.000007      2.332745             10                9       13   \n",
       "42          0.000014      6.957568            133                4      165   \n",
       "1            0.00034      3.557922             22               58        2   \n",
       "47          0.000013      9.389501            102                1        3   \n",
       "45          0.132742      4.131661             15                2        6   \n",
       "4           1.624653      8.334376              8                5      215   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "13         0.868881        0.002324                1  \n",
       "31         0.867134        0.001341                2  \n",
       "20         0.863749        0.000733                3  \n",
       "27         0.854222        0.000932                4  \n",
       "10         0.851656        0.000222                5  \n",
       "9          0.851110        0.000706                6  \n",
       "17         0.850154        0.000031                7  \n",
       "14         0.847752        0.000195                8  \n",
       "41         0.846223        0.000195                9  \n",
       "8          0.843411        0.000932               10  \n",
       "2          0.835768        0.002507               11  \n",
       "36         0.831973        0.000523               12  \n",
       "3          0.826540        0.000496               13  \n",
       "30         0.826158        0.000387               14  \n",
       "23         0.817532        0.000879               15  \n",
       "19         0.811471        0.000268               16  \n",
       "33         0.810106        0.000868               17  \n",
       "6          0.807649        0.000387               18  \n",
       "37         0.804646        0.000814               19  \n",
       "15         0.800633        0.002107               20  \n",
       "16         0.796648        0.002654               21  \n",
       "35         0.796102        0.000306               22  \n",
       "29         0.792416        0.005290               23  \n",
       "26         0.790069        0.014681               24  \n",
       "25         0.788267        0.002397               25  \n",
       "5          0.784527        0.015145               26  \n",
       "28         0.784308        0.004565               27  \n",
       "21         0.778767        0.003543               28  \n",
       "22         0.770168        0.021260               29  \n",
       "11         0.760449        0.001495               30  \n",
       "40         0.758947        0.000007               31  \n",
       "38         0.758947        0.000007               31  \n",
       "39         0.758947        0.000007               31  \n",
       "44         0.758947        0.000007               31  \n",
       "0          0.758947        0.000007               31  \n",
       "34         0.758947        0.000007               31  \n",
       "32         0.758947        0.000007               31  \n",
       "24         0.758947        0.000007               31  \n",
       "12         0.758947        0.000007               31  \n",
       "7          0.758947        0.000007               31  \n",
       "49         0.758947        0.000007               31  \n",
       "43         0.706722        0.057746               42  \n",
       "18         0.674126        0.099133               43  \n",
       "48         0.665011        0.000073               44  \n",
       "46         0.539536        0.243058               45  \n",
       "42         0.514673        0.001979               46  \n",
       "1          0.499218        0.153217               47  \n",
       "47         0.403453        0.104518               48  \n",
       "45         0.402285        0.107952               49  \n",
       "4          0.257050        0.013220               50  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_results = [\n",
    "    f\"param_{name}\" for name in param_distributions.keys()]\n",
    "column_results += [\n",
    "    \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "\n",
    "cv_results = pd.DataFrame(model_random_search.cv_results_)\n",
    "cv_results = cv_results[column_results].sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "cv_results = cv_results.rename(shorten_param, axis=1)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"max_leaf_nodes\": cv_results[\"max_leaf_nodes\"],\n",
    "        \"learning_rate\": cv_results[\"learning_rate\"],\n",
    "        \"score_bin\": pd.cut(\n",
    "            cv_results[\"mean_test_score\"], bins=np.linspace(0.5, 1.0, 6)\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "sns.set_palette(\"YlGnBu_r\")\n",
    "ax = sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"max_leaf_nodes\",\n",
    "    y=\"learning_rate\",\n",
    "    hue=\"score_bin\",\n",
    "    s=50,\n",
    "    color=\"k\",\n",
    "    edgecolor=None,\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "_ = ax.legend(title=\"mean_test_score\", loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "learning_rate",
           "values": [
            -0.669058858424374,
            -1.464034203538401,
            0.01958116509746725,
            -1.0913066440520454,
            -1.2341662931972524,
            0.1834312947178125,
            -1.2455009508737866,
            -1.7953823740054755,
            -1.228964901847501,
            -1.734575243833048,
            -1.8427188253963709,
            -1.6969896786225176,
            -0.9899636948988202,
            -1.0765187789854158,
            -1.218899395621584,
            -1.486526537618316,
            0.27991260856748346,
            -0.3384828154543537,
            -2.1848188432390643,
            -1.5590960100035032,
            -1.281837747137415,
            -2.028879715390699,
            0.19964993008179688,
            0.3214632757183914,
            -2.1041801591841285,
            -2.364408473608447,
            -1.8424622749091166,
            -1.800080967001667,
            0.6169321941536681,
            -2.0509676364303604,
            -2.9557919274305875,
            -2.816253195706388,
            -2.622422794134311,
            -2.60423658135678,
            -2.811894631856485,
            -2.4318116168104913,
            -2.5307670987985222,
            -2.5158589860827214,
            -2.420298277191175,
            -2.2538503013413913,
            -2.6144462051519173,
            0.48751597236408184,
            0.2579000186154259,
            0.15338247913029252,
            0.3678672875434495,
            0.8424574308508626,
            0.5511963819669088,
            0.9726424931594777,
            0.6161246815438939,
            0.9208731028516902
           ]
          },
          {
           "label": "max_leaf_nodes",
           "values": [
            4.392317422778761,
            6.20945336562895,
            5.930737337562887,
            4.523561956057013,
            2.584962500721156,
            4.523561956057013,
            7.599912842187128,
            7.7615512324444795,
            3,
            6.78135971352466,
            4.321928094887363,
            2.807354922057604,
            4.643856189774724,
            5.459431618637297,
            1,
            3.9068905956085187,
            7.857980995127572,
            1.584962500721156,
            2.807354922057604,
            4.584962500721156,
            1,
            6.459431618637297,
            4.700439718141092,
            4.523561956057013,
            3.807354922057604,
            5.129283016944966,
            1,
            1.584962500721156,
            6.882643049361842,
            1.584962500721156,
            2.321928094887362,
            1.584962500721156,
            7.6865005271832185,
            4.459431618637297,
            4.247927513443585,
            3.700439718141092,
            3,
            3.321928094887362,
            4.584962500721156,
            1,
            7.864186144654281,
            2.584962500721156,
            2.807354922057604,
            1,
            3.321928094887362,
            7.05528243550119,
            4.459431618637297,
            6.672425341971495,
            3.9068905956085187,
            3
           ]
          },
          {
           "label": "max_bins",
           "values": [
            7.622051819456376,
            7.562242424221073,
            7.900866807980749,
            5.643856189774724,
            6.20945336562895,
            7.05528243550119,
            4.247927513443585,
            5.321928094887363,
            3.9068905956085187,
            3.9068905956085187,
            4,
            6.108524456778169,
            2.584962500721156,
            2.321928094887362,
            7.515699838284043,
            2,
            6.930737337562887,
            1.584962500721156,
            6.794415866350106,
            1,
            4.807354922057604,
            1.584962500721156,
            5.357552004618084,
            3.700439718141092,
            3.584962500721156,
            5.321928094887363,
            4.523561956057013,
            2,
            3.4594316186372973,
            5.20945336562895,
            2.584962500721156,
            2.807354922057604,
            2,
            5.930737337562887,
            4,
            6.022367813028454,
            6.285402218862249,
            7.721099188707185,
            5.357552004618084,
            7.700439718141092,
            1,
            5.672425341971495,
            2,
            3.169925001442312,
            3.700439718141092,
            7.366322214245816,
            1,
            1.584962500721156,
            2.584962500721156,
            7.7481928495894605
           ]
          },
          {
           "label": "min_samples_leaf",
           "values": [
            1.0791812460476249,
            0.47712125471966244,
            0.47712125471966244,
            0.47712125471966244,
            1.5797835966168101,
            1.806179973983887,
            1.568201724066995,
            1.8864907251724818,
            1.9344984512435677,
            1.7708520116421442,
            0.6020599913279624,
            0,
            1.3979400086720377,
            0.9542425094393249,
            0,
            0.6020599913279624,
            1.4913616938342726,
            1.3222192947339193,
            1.7403626894942439,
            1.6720978579357175,
            0,
            1.591064607026499,
            1.6812412373755872,
            1.8573324964312685,
            0.9030899869919435,
            0.3010299956639812,
            0,
            0.7781512503836436,
            0,
            1.6812412373755872,
            0.47712125471966244,
            1.2304489213782739,
            0.6989700043360189,
            0.9542425094393249,
            0,
            1,
            1.2041199826559248,
            1.5440680443502757,
            0.9030899869919435,
            1.9138138523837167,
            0,
            0,
            1.2041199826559248,
            1.6127838567197355,
            0.9542425094393249,
            0.6020599913279624,
            1.7634279935629373,
            0,
            0.3010299956639812,
            0.6989700043360189
           ]
          },
          {
           "label": "l2_regularization",
           "values": [
            -2.964413327838944,
            -4.955420954750229,
            1.9313369346872966,
            2.622996579104787,
            -4.974634158867468,
            0.6685360168217497,
            -3.8356048713539534,
            0.9808117232995444,
            1.3704824820022539,
            -0.11125908256324729,
            0.5959236955237498,
            -0.09728672682002715,
            2.849069814843885,
            -2.545235850788036,
            -4.8608228928372235,
            -2.5944879313589135,
            -0.011143526660287175,
            -1.0972965274271944,
            0.5506026257206695,
            1.4099308527081609,
            1.8431932489396547,
            -2.6409666975297803,
            -1.641420868692767,
            -1.4721913544883691,
            -3.8782155872265323,
            -1.17619592842243,
            0.8920691535251553,
            -1.4290611794373138,
            2.2544786722482004,
            1.6351848366996724,
            -5.977123093799937,
            -2.786311965647711,
            -3.322203465035393,
            0.4989288684419486,
            -3.7860071190200046,
            1.8548175600598957,
            2.664059233193529,
            -3.7718895283876055,
            -0.050569560996979984,
            0.7705675348116694,
            -3.7823477163947143,
            -0.8905318827975719,
            -1.3873423841670942,
            -5.687580221204337,
            -5.149109902823555,
            -4.867335362746308,
            -3.4689006735640575,
            -4.903011890918568,
            -0.8769923729399828,
            0.21076063979707776
           ]
          },
          {
           "label": "mean_test_score",
           "values": [
            0.8261581614770084,
            0.7589473395053217,
            0.7966475757259771,
            0.7787667151556648,
            0.8357675877549213,
            0.8434112928271041,
            0.8076492482476322,
            0.8175315749349381,
            0.7067222367397078,
            0.8462231389999462,
            0.8637493034140774,
            0.7589473395053217,
            0.8542218085185982,
            0.7589473395053217,
            0.7900689219863712,
            0.8006332858101803,
            0.7589473395053217,
            0.8501542400865397,
            0.7589473395053217,
            0.8114711656205432,
            0.8101062179135994,
            0.7589473395053217,
            0.7604488410068231,
            0.7843082480721704,
            0.7845271803996416,
            0.8511097350800343,
            0.7701679249779272,
            0.7961016541765613,
            0.7924164038763297,
            0.8319729048272398,
            0.7589473395053217,
            0.7589473395053217,
            0.7589473395053217,
            0.5395363747078095,
            0.8688814849712425,
            0.7589473395053217,
            0.7589473395053217,
            0.7882668340082623,
            0.8265403484446944,
            0.8477518987947028,
            0.25705040047691285,
            0.6650105122096823,
            0.8046463600132523,
            0.40228516699907835,
            0.49921778774148284,
            0.6741257641727176,
            0.8671343577491208,
            0.40345323584021986,
            0.5146733100707768,
            0.8516556953824916
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           0.8261581614770084,
           0.7589473395053217,
           0.7966475757259771,
           0.7787667151556648,
           0.8357675877549213,
           0.8434112928271041,
           0.8076492482476322,
           0.8175315749349381,
           0.7067222367397078,
           0.8462231389999462,
           0.8637493034140774,
           0.7589473395053217,
           0.8542218085185982,
           0.7589473395053217,
           0.7900689219863712,
           0.8006332858101803,
           0.7589473395053217,
           0.8501542400865397,
           0.7589473395053217,
           0.8114711656205432,
           0.8101062179135994,
           0.7589473395053217,
           0.7604488410068231,
           0.7843082480721704,
           0.7845271803996416,
           0.8511097350800343,
           0.7701679249779272,
           0.7961016541765613,
           0.7924164038763297,
           0.8319729048272398,
           0.7589473395053217,
           0.7589473395053217,
           0.7589473395053217,
           0.5395363747078095,
           0.8688814849712425,
           0.7589473395053217,
           0.7589473395053217,
           0.7882668340082623,
           0.8265403484446944,
           0.8477518987947028,
           0.25705040047691285,
           0.6650105122096823,
           0.8046463600132523,
           0.40228516699907835,
           0.49921778774148284,
           0.6741257641727176,
           0.8671343577491208,
           0.40345323584021986,
           0.5146733100707768,
           0.8516556953824916
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "mean_test_score"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.parallel_coordinates(\n",
    "    cv_results.apply(\n",
    "        {\n",
    "            \"learning_rate\": lambda x : np.log10(x.astype(np.float64)),\n",
    "            \"max_leaf_nodes\": lambda x : np.log2(x.astype(np.int64)),\n",
    "            \"max_bins\": lambda x : np.log2(x.astype(np.int64)),\n",
    "            \"min_samples_leaf\": lambda x : np.log10(x.astype(np.float64)),\n",
    "            \"l2_regularization\": lambda x : np.log10(x.astype(np.float64)),\n",
    "            \"mean_test_score\": lambda x: x,\n",
    "        }\n",
    "    ),\n",
    "    color=\"mean_test_score\",\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ 5\n",
    "\n",
    "**1.What does CV stand for in GridSearchCV and why?**\n",
    "\n",
    "a) cross-validation : once we found the best parameters we estimate the model performance through cross-validation on the full data\n",
    "\n",
    "b) circular values: we do a permutation of all the possible parameter value combinations\n",
    "\n",
    "c) cross-validation: the score of each combination of parameters on the grid is computed by using an internal cross-validation procedure\n",
    "\n",
    "d) contribution value : we estimate how much each parameter contributes to the model generalization performance\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**2.Select the true statements about RandomizedSearchCV and GridSearchCV below:**\n",
    "\n",
    "a) RandomizedSearchCV has a fixed computation budget through its n_iter parameter\n",
    "\n",
    "b) RandomizedSearchCV allows to test all the combinations of a fixed set of parameter values\n",
    "\n",
    "c) GridSearchCV can become very computationally intensive when the number of parameters grows\n",
    "\n",
    "d) both GridSearchCV and RandomizedSearchCV have the attributes cv_results_ and best_params_ \n",
    "\n",
    "e) both GridSearchCV and RandomizedSearchCV can use probability distributions to draw parameter values from\n",
    "\n",
    "<br>\n",
    "\n",
    "Given `pipeline` defined by:\n",
    "\n",
    "<code>\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = ...  # complete this line in your answer\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid\n",
    ").fit(X, y)\n",
    "\n",
    "model.best_params_\n",
    "\n",
    "</code>\n",
    "\n",
    "**3. If we want to find the best C through `GridSearchCV` which of the below is the currect answer to set the `param_grid` with values as `0.1, 1, and 10` ?**\n",
    "\n",
    "a) param_grid = {'logisticregression__C': [0.1, 1, 10]}\n",
    "\n",
    "b) param_grid = {'classifier__C': [0.1, 1, 10]}\n",
    "\n",
    "c) param_grid = {'classifier__C': 0.1, 'classifier__C': 1, 'classifier__C': 10}\n",
    "\n",
    "d) param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation Returns\n",
    "\n",
    "Though we learned two approaches to tune hyperparameters, we did not present a proper framework to evaluate the tuned models. \n",
    "\n",
    "Instead, we focused on the mechanism used to find the best set of parameters. Thus, we look at the cross-validation again from the lens of hyperparameters tuning while evaluating models.\n",
    "\n",
    "When calling the fit method for `GridSearchCV`, the model embedded in the grid-search is trained with every possible combination of parameters resulting from the parameter grid. The best combination is selected by keeping the combination leading to the best mean cross-validated score.\n",
    "\n",
    "In the case of `RandomizedSearchCV`, the cross-validation follows the same approach. \n",
    "\n",
    "The mean and standard deviation of the scores computed by the cross-validation in the `GridSearchCV` is potentially not reasonable estimates of the generalization performance. We could primarily obtain the generalization performance by refitting a model with the best combination of hyper-parameter values on the full dataset.\n",
    "\n",
    "*Note that scikit-learn automatically performs this refit by default when calling model_grid_search.fit.*\n",
    "\n",
    "This refitted model is trained with more data than the different models trained internally during the cross-validation of the `GridSearchCV`.\n",
    "\n",
    "Therefore, we use knowledge from the entire dataset to decide our model's hyper-parameters and train the refitted model.\n",
    "\n",
    "And thus, one must apply techniques to evaluate the refitted model on unseen data.\n",
    "\n",
    "<br>\n",
    "\n",
    "*** \n",
    "\n",
    "**1. Single train-test split.**\n",
    "\n",
    "We first split the data into test and train sets.\n",
    "\n",
    "The selection of the best hyperparameters is made only on the train set from the initial train-test split. \n",
    "\n",
    "Then, we evaluate the generalization performance of our tuned model on the left-out test set, demonstrated schematically below.\n",
    "\n",
    "![Cross-validation tuning with test train split](../figures/cross_validation_train_test_diagram.png)\n",
    "\n",
    "This figure shows the K-fold cross-validation strategy using n_splits=5 to split further the train set coming from a train-test split. \n",
    "The procedure trains a model on all the red samples for each cross-validation split. It then evaluates the score of a given set of hyperparameters on the green samples. \n",
    "The best hyper-parameters are selected based on those intermediate scores. Then a final model tuned with those hyper-parameters is fitted on the concatenation of the red and green samples and evaluated on the blue samples.\n",
    "\n",
    "The green samples are sometimes called validation sets to differentiate them from the final test set in blue.\n",
    "\n",
    "*** \n",
    "\n",
    "<br>\n",
    "\n",
    "However, the above evaluation only provides a single-point estimate of the generalization performance. But it is beneficial to have a rough idea of the uncertainty of our estimated generalization performance. Therefore, we should instead use additional cross-validation for the evaluation. This pattern is called nested cross-validation.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "**2. Nested cross-validation** \n",
    "\n",
    "In this approach, we use inner cross-validation to select the hyperparameters and outer cross-validation to evaluate the generalization performance of the refitted tuned model. \n",
    "\n",
    "We only need to embed the grid-search/randomized-search in the function cross-validate to perform such evaluation.\n",
    "\n",
    "\n",
    "Below is a schematic representation of the complete nested cross-validation\n",
    "procedure:\n",
    "\n",
    "![Nested cross-validation tuning](../figures/nested_cross_validation_diagram.png)\n",
    "\n",
    "\n",
    "This figure illustrates the nested cross-validation strategy using cv_inner = KFold(n_splits=4) and cv_outer = KFold(n_splits=5).\n",
    "\n",
    "For each inner cross-validation split (indexed on the left-hand side), the procedure trains all red samples. It evaluates the hyperparameters' quality on the green samples.\n",
    "\n",
    "For each outer cross-validation split (indexed on the right-hand side), the best hyper-parameters are selected based on the validation scores (computed on the green samples). A model is refitted on the concatenation of the red and green samples for that outer CV iteration.\n",
    "\n",
    "The generalization performance of the five refitted models from the outer CV loop is then evaluated on the blue samples to get the final scores.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redoing and reloading to keep things in same view \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "target_name = \"class\"\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
    "\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat_preprocessor', categorical_preprocessor, categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\n",
    "        \"classifier\",\n",
    "        HistGradientBoostingClassifier(\n",
    "            random_state=42, max_leaf_nodes=4\n",
    "        )\n",
    "    ),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': (0.01, 0.1),\n",
    "    'classifier__max_leaf_nodes': (3, 10)\n",
    "}\n",
    "\n",
    "model_grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=2,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Accuracy on test set: 0.877\n"
     ]
    }
   ],
   "source": [
    "# 1 . Single test train split \n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_grid_search.fit(data_train, target_train)\n",
    "accuracy = model_grid_search.score(data_test, target_test)\n",
    "print(f\"Accuracy on test set: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Generalization score with hyperparameters tuning:\n",
      "0.870 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "# 2 . Nested cross-validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(\n",
    "    model_grid_search, data, target, cv=5, n_jobs=2, return_estimator=True\n",
    ")\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_test_scores = cv_results['test_score']\n",
    "print(\n",
    "    \"Generalization score with hyperparameters tuning:\\n\"\n",
    "    f\"{cv_test_scores.mean():.3f} +/- {cv_test_scores.std():.3f}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for fold #1:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 10}\n",
      "Best hyperparameters for fold #2:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 10}\n",
      "Best hyperparameters for fold #3:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 10}\n",
      "Best hyperparameters for fold #4:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 10}\n",
      "Best hyperparameters for fold #5:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 10}\n"
     ]
    }
   ],
   "source": [
    "for cv_fold, estimator_in_fold in enumerate(cv_results[\"estimator\"]):\n",
    "    print(\n",
    "        f\"Best hyperparameters for fold #{cv_fold + 1}:\\n\"\n",
    "        f\"{estimator_in_fold.best_params_}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d1d2e3121d0b20776376c643d68565d9e63b38fe6258debd2f2fdfbf80c13c2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml_with_sk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
